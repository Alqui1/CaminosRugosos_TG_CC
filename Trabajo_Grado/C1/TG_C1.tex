
\chapter{Preliminares}


En este capítulo, nos dedicaremos a repasar conceptos de teoría de la probabilidad, teoría de integración y ecuaciones diferenciales estocásticas. Para una mayor información, en cada sección


% ========================================
%================ SECCIÓN 1. PROBABILIDAD
% ========================================



% ========================================
%================ SECCIÓN 1.1 Espacios de probabilidad.
% ========================================



\section{Conceptos de Probabilidad.}

\subsection{Espacios de probabilidad.}

Sea $\Omega$ un conjunto abstracto. Denotamos por $2^{\Omega}$ el conjunto de partes de $\Omega$.

\begin{boxDef}
Definimos a $\mathcal{F}$ una $\mathbf{\sigma}$\textbf{-álgebra} es subconjunto de $2^{\Omega}$ que cumple las siguientes propiedades:

	\begin{itemize}
		\item $\emptyset$, $\Omega$ $\in \mathcal{F}$
		\item Si $A \in \mathcal{A}$, luego $A^{c} \in \mathcal{A}$
		\item Dado $\{ A_i \}_{i \in I}$ una sucesión de subconjuntos de $\Omega$ a lo más contable. Luego, si para todo $i \in I$, $A_i \in \mathcal{A}$, entonces $\cup_{i \in I} A_i \in \mathcal{A}$ 
	\end{itemize}

El espacio $\left( \Omega, \mathcal{A} \right)$ se llama \textbf{espacio medible}.

\end{boxDef}



Los elementos en $\mathcal{A}$ se llamarán \textit{eventos}.



\textbf{Ejemplo:}

\begin{itemize}

	\item Para $\Omega$ un conjunto abstracto, $\mathcal{A} = \left\{ \emptyset, \Omega \right\}$ es la $\sigma$-álgebra trivial. 

	\item Sea $A \subset \Omega$, entonces $\sigma(A) = \left\{ \emptyset, A, A^c, \Omega \right\}$ también es una $\sigma$-álgebra, llamada la \textbf{menor} $\mathbb{\sigma}$-\textbf{álgebra} que contiene a $A$, que se genera mediante la intersección de todas las $\sigma$-álgebras que contienen a $A$. 

	\item Para $\Omega = \mathbb{R}$, una $\sigma$-álgebra para este conjunto es la $\sigma$-\textbf{álgebra de Borel}, que se puede generar con intervalos de la forma $(-\infty, a]$ para todo $a \in \mathbb{Q}$. También, es la generada por todos los conjuntos abiertos (O cerrados, o semiabiertos...). Para más información consulte CITAR DONALD COHN Y PROTTER.  

\end{itemize}

\begin{flushright}
	$\Box$
\end{flushright}


\begin{boxDef}
	Una \textbf{medida de probabilidad} definida en una $\sigma$-álgebra $\mathcal{A}$ de $\Omega$, es una función $P: \mathcal{A} \rightarrow [0,1]$ que cumple:

	\begin{itemize}
		\item $P(\Omega) =  1$\\
		\item Para toda colección contable $\left\{ A_n \right\}_{n \geq 1}$ de elementos en $\mathcal{A}$ que son disyuntos par a par, se tiene:

		\[
			P\left( \cup_{n=1}^{\infty}  \right) = \sum_{n = 1}^{\infty} P\left( A_n \right)
		\]

		Es decir, la función es \textit{contablemente aditiva}. Se llama a $P(A)$ como la \textit{probabilidad del evento A}.

	\end{itemize}

La tripla $(\Omega, \mathcal{A}, P)$ se conoce como \textbf{espacio de probabilidad}.

\end{boxDef}

De forma general, la medida de probabilidad, es un caso específico de una \textit{función de medida}, en este caso, tendremos un \textit{espacio de medida}. Vea COHN.\\

Note que, podemos ver una propiedad más débil que el axioma (2) en la anterior definición. Para toda colección $\left\{  A_k \right\}_{k = 1}^{n}$ \textit{finita}, de disyuntos par a par, si tenemos:

\[
	P\left( \cup_{k=1}^n A_k \right) = \sum_{k = 1}^{n} P(A_k)
\]
entonces la función $P$ es \textbf{aditiva (O finitamente aditiva)}.

Vamos a revisar algunas propiedades de las funciones de probabilidad, sin demostración. Para consultar los detalles, puede consultar PROTTER.

\begin{theorem}
	Sea $(\Omega, \mathcal{A})$ un espacio medible, y $P: \mathcal{A} \rightarrow [0,1]$ una función finitamente aditiva y $P(\Omega) = 1$. Entonces, tenemos las siguientes equivalencias:

	\begin{itemize}
		\item La función es contablemente aditiva.
		\item Si $A_n \in \mathcal{A}$ y $A_n \downarrow \emptyset$, luego $P(A_n) \downarrow 0$.
		\item Si $A_n \in \mathcal{A}$ y $A_n \downarrow A$, luego $P(A_n) \downarrow P(A)$.
		\item Si $A_n \in \mathcal{A}$ y $A_n \uparrow \Omega$, luego $P(A_n) \uparrow 1$.
		\item Si $A_n \in \mathcal{A}$ y $A_n \uparrow A$, luego $P(A_n) \uparrow P(A)$.
	\end{itemize}

	Más aún, si $P$ es una medida de probabilidad, y dado $\left\{ A_n \right\}$ sucesión de eventos que converge a $A$. Entonces $A \in \mathcal{A}$ y $\lim_{n \rightarrow \infty} P(A_n) = P(A)$ 

\end{theorem}


% ¿Colocar teorema de la clase monótona?


% ========================================
%================ SECCIÓN 1.2 Variables aleatorias.
% ========================================

% AÑADIR VARIABLES ALEATORIAS DISCRETAS Y CONTINUAS

\subsection{Variables aleatorias.}

En esta sección, tommaos a $(\Omega, \mathcal{A}, P)$ un espacio abstracto, donde $\Omega$ no es necesariamente contable.

\begin{boxDef}
	Sean $(E, \mathcal{E})$ y $(F, \mathcal{F})$ dos espacios medibles (No necesariamente tienen una medida de probabilidad). Una función $X: E \rightarrow F$ es una \textbf{función medible} si $X^{-1}(\Lambda) \in \mathcal{E}$ para todo $\Lambda \in \mathcal{F}$.\\

	Si $(E, \mathcal{E}, P)$ es un espacio de probabilidad, $X$ posee el nombre de \textbf{variable aleatoria}.
\end{boxDef}

Nuevamente, tenemos varias propiedades para las funciones medibles, que enunciaremos acá, sin la demostración respectiva. Para esto, consulte, PROTTER.

\begin{coro}
	Sea $(E, \mathcal{E})$ un espacio medible aleatorio, y $(\mathbb{R}, \mathcal{B})$. Sea $X, X_n: E \rightarrow \mathbb{R}$ funciones:

	\begin{itemize}
		\item X es medible si y sólo si $\left\{ X \leq a \right\} = X^{-1}( (-\infty, a] ) \in \mathcal{E}$, para todo $a \in \mathbb{R}$.
		\item Si cada $X_n$ es medible, luego $\sup X_n$, $\inf X_n$, $\limsup X_n$ y $\liminf X_n$ son medibles.
		\item Si cada $X_n$ es medible, y $\left\{X_n\right\}$ converge puntualmente a $X$, luego $X$ es medible. 
	\end{itemize}

\end{coro}

\begin{theorem} 
	Sea $X$ medible de $(E, \mathcal{E})$ en $(F, \mathcal{F})$, y $Y$ medible de $(F, \mathcal{F})$ en $(G, \mathcal{G})$. Entonces, $Y \circ X$ es medible de $(E, \mathcal{E})$ en $(G, \mathcal{G})$.
\end{theorem}

\begin{theorem}
	Sean $(E, \mathcal{U})$ y $(F, \mathcal{V})$ espacios topológicos, y $\mathcal{E}$, $\mathcal{F}$ sus $\sigma$-álgebras de Borel (generada por los abiertos), respectivamente. Entonces, cada función continua $X: E \rightarrow F$ es medible (O también llamada, \textit{función boreliana}).
\end{theorem}

Recuerde que, \textit{la función indicadora}, $f(x) = 1_A (x)$ se define como:

\[
	1_A (x) = \left\{  \begin{array}{lc}
		0 & x \in A \\
		1 & x \notin A
	\end{array} \right\}
\]

\begin{theorem}
	Sea $(F, \mathcal{F}) = (\mathbb{R}, \mathcal{B})$ y $(E, \mathcal{E})$ un espacio medible.

	\begin{itemize}
		\item Función indicadora $1_A$ en $E$ es medible si y sólo sí $A \in \mathcal{E}$
		\item Si $X_1, \cdots, X_n$ son funciones medibles de $(E, \mathcal{E})$ en $(\mathbb{R}, \mathcal{B})$, y si $f$ es borel en $\mathbb{R}^n$, luego $f(X_1, \cdots, X_n)$.
		\item Si $X, Y$ son medibles, luego $X + Y$, $XY$, $\max(X,Y)$, $\min{X,Y}$ y $X/Y$ con $Y \neq 0$ son medibles.
	\end{itemize}

\end{theorem}

Recordemos, para $X$ una variable aleatoria, será una función entre los espacios medibles $(\Omega, \mathcal{A})$ y $(E, \mathcal{E})$. Si dotamos al primer espacio de una probabilidad, $P$, de forma canónica podemos dotar al segundo espacio, de una medida de probabilidad, según $X$.

\begin{boxDef}
	Si $X$ es una variable aleatoria entre $(\Omega, \mathcal{A}, P)$, con valores en $(E, \mathcal{E})$, la \textbf{distribución} (O \textbf{medida de distribución}) de $X$, está definida por:

	\[
		P^{X} (B) = P(X^{-1} (B)) =  P(\{ \omega : X(\omega) \in B \}) = P(X \in B)
	\] 

	para todo $B \in \mathcal{E}$. 
\end{boxDef}

	Como la inversa se comporta bien bajo uniones e intersecciones, no es muy dificil probar que:

\begin{theorem}
	La distribución de $X$ es una medida de probabilidad en $(E, \mathcal{E})$
\end{theorem}

	Si $X$ es una variable aleatoria en $\mathbb{R}$, $P^{X}$ es una probabilidad en los reales, caracterizada por la función:

	\[
		F_X (x) = P^{X} ( (-\infty, x] ) = P(X \leq x)
	\]

	por el hecho, que los elementos en los borelianos, $\mathcal{B}$, pueden ser generador por elementos de la forma $(-\infty, x]$. $F_X (x)$ se conoce como \textbf{función de distribución cumulativa}.



% ========================================
%================ SECCIÓN 1.3 Valor esperado. Integración bajo el signo de la integral.
% ========================================


\subsection{Integración respecto a medida de probabilidad. Valor esperado.}

Dada una variable aleatoria, en un espacio de probabilidad $(\Omega, \mathcal{A}, P)$, podríamos determinar un valor esperado, un promedio ponderado según la probabilidad, la imagen que se espera que tenga la variable aleatoria. \\

Para una variable aleatoria discreta, tenemos la definición:

% AGREGAR DEFINICIÓN PARA V.A DISCRETA

Ahora, queremos hallar el valor esperado para variables aleatorias en general. Consideramos algunos casos especiales inicialmente:

\begin{boxDef}
	Una variable aleatoria $X$ es \textbf{simple} si su imagen es un conjunto finito, por ende, para una familia de conjuntos disyuntos medibles, $ \left\{ A_i  \right\} \subset \mathcal{A}$, y constantes, $a_i \in \mathbb{R}$, para $1 \leq i \leq n$, veremos que la variable aleatoria tiene la forma:

	\[
		X = \sum_{i = 1}^n a_i 1_{A_i}
	\]

	Para $X$ variable aleatoria simple, podemos definir su \textbf{integral respecto a $P$} o \textbf{valor esperado} como:

	\[
		\mathbb{E}[X] = \sum_{i = 1}^n a_i P(A_i)
	\]
	o también denotado por $\int X dP$.

\end{boxDef}

Ahora, deseamos extender la definición para funciones más generales. Para esto, tendremos en cuenta los siguientes resultados:

\begin{theorem}
	Para cada variable aleatoria positiva $X$, existe una sucesión de variables aleatorias simples $\left\{ A_n \right\}_{n \geq 1}$ tal que $X_n$ tiende a $X$ de forma creciente, para $n \rightarrow \infty$ 
\end{theorem}

\textbf{Demostración:} Podemos tomar la sucesión:

\[
	X_n (\omega) = \left\{ \begin{matrix}
		k 2^{-n} & \text{si } k 2^{-n} \leq X(\omega) < (k+1) 2^{-n} \text{ y } 0 \leq k \leq n 2^n - 1 \\
		n & \text{si } X(\omega) \geq n
	\end{matrix}
	 \right.
\]

AÑADIR UNA GRAFICA

\begin{flushright}
	$\Box$
\end{flushright}


\begin{theorem}
	Sea $X$ una variable aleatoria positiva. Si $\left\{ X_n \right\}$ es sucesión de variables aleatorias simples que tienden de forma creciente a $X$, entonces $\mathbb{E}[X_n]$ tiende a $\mathbb{E}[X]$
\end{theorem}

Primero, podemos definir el valor esperado para variables aleatorias en positivas, esto es, que toma valores en $[0, \infty )$, como:

\[
	\int X dP = \mathbb{E}[X] = \sup \left\{ \mathbb{E}[Y] : Y \text{ es función simple con } 0 \leq Y \leq X \right\}
\]

De este modo, podemos definir:

\begin{boxDef}
	Sea $X^+ = \max (X, 0)$ y $X^- = -\min (X, 0)$. Una variable aleatoria $X$ es \textbf{integrable} si $\mathbb{E}[X^+] < \infty$ y $\mathbb{E}[X^-] < \infty$. En este caso, el \textbf{valor esperado} de $X$ se define como:

	\[
		\int X dP = \mathbb{E}[X] = \int X^+ dP + \int X^- dP = \mathbb{E}[X^+] + \mathbb{E}[X^-]
	\] 

	Tenemos que $\mathcal{L}^1$ o $\mathcal{L}^1 (\Omega, \mathcal{A}, P)$, es el conjunto de variables aleatorias que son integrables. \\ 

	% Admite valor esperado?

\end{boxDef}

Ya estamos listos para enunciar varias propiedades importantes de las variables aleatorias.

\begin{theorem}
	\begin{itemize}
		\item $\mathcal{L}^1$ es espacio vectorial, donde $\mathbb{E}$ es operador lineal, y para $X \in \mathcal{L}^1$ tal que $X \geq 0$, luego $\mathbb{E}[X] \geq 0$. Más aún, para $X \leq Y$, tenemos que $\mathbb{E}[X] \leq \mathbb{E}[Y]$.
		\item $X \in \mathcal{L}^1$ si y sólo si $| X | \in \mathcal{L}^1$.
		\item $\left\lvert \mathbb{E}[X] \right\rvert \leq \mathbb{E}[ \left\lvert X \right\rvert ]$. Mas aún, cualquier variable aleatoria acotada es integrable.
		\item Si $X = Y$ \textit{casi siempre} (Esto es, que $P(X = Y) = P(\left\{ \omega : X(\omega) = Y(\omega) \right\}) = 1$), entonces, $\mathbb{E}[X] = \mathbb{E}[Y]$. 
	\end{itemize}	

\end{theorem}

\begin{theorem}[Teorema de la convergencia monótona.]
	Si las variables aleatorias $X_n$ son positivas y tienden de forma creciente \textit{casi siempre} a X, luego $\lim_{n \rightarrow \infty} \mathbb{E}[X_n] = \mathbb{E}[X]$.
\end{theorem}

% ¿Esto está bien?
En este caso, $X_n$ tienden de forma creciente \textit{casi siempre} a X, si \\$P( \left\{ \omega : \lim_{n \rightarrow \infty } X_n (w) = X_n \right\} ) = 1$.

\begin{lema}[Lema de Fatou]
	Si las variables aleatorias $X_n$ satisfacen $X_n \geq Y$ \textit{casi siempre} ( $P( X_n \leq Y ) = P( \left\{ \omega : X_n(\omega) \leq Y(\omega) \right\}) = 1$ ) con $Y \in \mathcal{L}^1$, para todo $n$, entonces:

	\[
		\mathbb{E}\left[\liminf_{n \rightarrow \infty} X_n\right] \leq \liminf_{n \rightarrow \infty} \mathbb{E}[X_n]
 	\]

 	o se puede escribir como:

 	\[
 		\int_{\Omega} \liminf_{n \rightarrow \infty} X_n \leq \liminf_{n \rightarrow \infty} \int_{\Omega}  X_n
 	\]

 	En particular, si $X_n \leq 0$ \textit{casi siempre} para todo $n$, entonces se cumple la desigualdad.

\end{lema}

\begin{theorem}[Teorema de la convergencia dominada de Lebesgue]
	Si las variables aleatorias $X_n$ convergen \textit{casi siempre} a $X$ y si $\lvert X_n \rvert \leq Y$ \textit{casi siempre} para $Y \in \mathcal{L}^1$, para todo $n$, entonces, $X_n, X \in \mathcal{L}^1$, y:

	\[
		\lim_{n \rightarrow \infty } \mathbb{E}[X_n] = \mathbb{E}[X]
	\] 

	o

	\[
		\lim_{n \rightarrow \infty } \int_{\Omega} X_n = \int_{\Omega} X_n
	\]
\end{theorem}




% Variables aleatorias. OK

% Medida de probabilidad. OK

% Probabilidad Condicional.

% Independencia de variables aleatorias.

% Inegración respecto a medida de probabilidad.

% Variables aleatorias Gaussianas.

% Convergencia de esta mondá, Ley de los grandes números.

% Esperanza Condicional, L2 y Espacios de Hilbert.

% ¿Función característica, generadora de momentos, etc...?

% INTEGRACIÓN.
-
% Integración usual RS, Integral de Young. Conceptos de p-variación y $\alpha$-Hölder.

% Ecuaciones Diferenciales Ordinarias. EDO Controladas. ¿EDP?

% Teorema de Picard, Teorema de Peano.-