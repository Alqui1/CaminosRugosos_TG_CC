
\chapter{Preliminares}


En este capítulo, nos dedicaremos a repasar conceptos de teoría de la probabilidad, teoría de integración y ecuaciones diferenciales. 













% ========================================
%================ SECCIÓN 1. PROBABILIDAD
% ========================================










% ========================================
%================ SECCIÓN 1.1 Espacios de probabilidad.
% ========================================



\section{Conceptos de Probabilidad.}

En esta sección, daremos un breve repaso a conceptos esenciales en probabilidad, para poder entender mejor procesos estocásticos, y de igual forma, poder realizar la construcción de la integral de Itô. Para mayor información, puede consultar \cite{Probability_Essentials}, del cuál se basará la gran parte de este capítulo.

\subsection{Espacios de probabilidad.}

Sea $\Omega$ un conjunto abstracto. Denotamos por $2^{\Omega}$ el conjunto de partes de $\Omega$.

\begin{boxDef}
Definimos a $\mathcal{F}$ una $\mathbf{\sigma}$\textbf{-álgebra} de $\Omega$, como un subconjunto de $2^{\Omega}$ que cumple las siguientes propiedades:

	\begin{itemize}
		\item $\emptyset$, $\Omega$ $\in \mathcal{F}$
		\item Si $A \in \mathcal{A}$, luego $A^{c} \in \mathcal{A}$
		\item Dado $\{ A_i \}_{i \in I}$ una sucesión de subconjuntos de $\Omega$ a lo más contable. Luego, si para todo $i \in I$, $A_i \in \mathcal{A}$, entonces $\cup_{i \in I} A_i \in \mathcal{A}$ 
	\end{itemize}

El espacio $\left( \Omega, \mathcal{A} \right)$ se llama \textbf{espacio medible}.

\end{boxDef}



Los elementos en $\mathcal{A}$ se llamarán \textit{eventos}.



\textbf{Ejemplo:}

\begin{itemize}

	\item Para $\Omega$ un conjunto abstracto, $\mathcal{A} = \left\{ \emptyset, \Omega \right\}$ es la $\sigma$-álgebra trivial. 

	\item Sea $A \subset \Omega$, entonces $\sigma(A) = \left\{ \emptyset, A, A^c, \Omega \right\}$ también es una $\sigma$-álgebra, llamada la \textbf{menor} $\mathbb{\sigma}$-\textbf{álgebra} que contiene a $A$, que se genera mediante la intersección de todas las $\sigma$-álgebras que contienen a $A$. 

	\item Para $\Omega = \mathbb{R}$, una $\sigma$-álgebra para este conjunto es la $\sigma$-\textbf{álgebra de Borel}, que se puede generar con intervalos de la forma $(-\infty, a]$ para todo $a \in \mathbb{Q}$. También, es la generada por todos los conjuntos abiertos (O cerrados, o semiabiertos...). Para más información consulte \cite{Measure_Theory_DC} Y \cite{Probability_Essentials}

\end{itemize}

\begin{flushright}
	$\Box$
\end{flushright}


\begin{boxDef}
	Una \textbf{medida de probabilidad} definida en una $\sigma$-álgebra $\mathcal{A}$ de $\Omega$, es una función $P: \mathcal{A} \rightarrow [0,1]$ que cumple:

	\begin{itemize}
		\item $P(\Omega) =  1$\\
		\item Para toda colección contable $\left\{ A_n \right\}_{n \geq 1}$ de elementos en $\mathcal{A}$ que son disyuntos par a par, se tiene:

		\[
			P\left( \cup_{n=1}^{\infty}  \right) = \sum_{n = 1}^{\infty} P\left( A_n \right)
		\]

		Es decir, la función es \textit{contablemente aditiva}. Se llama a $P(A)$ como la \textit{probabilidad del evento A}.

	\end{itemize}

La tripla $(\Omega, \mathcal{A}, P)$ se conoce como \textbf{espacio de probabilidad}.

\end{boxDef}

De forma general, la medida de probabilidad, es un caso específico de una \textit{función de medida}, en este caso, tendremos un \textit{espacio de medida}. Vea COHN.\\

Note que, podemos ver una propiedad más débil que el axioma (2) en la anterior definición. Para toda colección $\left\{  A_k \right\}_{k = 1}^{n}$ \textit{finita}, de disyuntos par a par, si tenemos:

\[
	P\left( \cup_{k=1}^n A_k \right) = \sum_{k = 1}^{n} P(A_k)
\]
entonces la función $P$ es \textbf{aditiva (O finitamente aditiva)}.

Vamos a revisar algunas propiedades de las funciones de probabilidad, sin demostración. Para consultar los detalles, puede consultar PROTTER.

\begin{theorem}
	Sea $(\Omega, \mathcal{A})$ un espacio medible, y $P: \mathcal{A} \rightarrow [0,1]$ una función finitamente aditiva y $P(\Omega) = 1$. Entonces, tenemos las siguientes equivalencias:

	\begin{itemize}
		\item La función es contablemente aditiva.
		\item Si $A_n \in \mathcal{A}$ y $A_n \downarrow \emptyset$, luego $P(A_n) \downarrow 0$.
		\item Si $A_n \in \mathcal{A}$ y $A_n \downarrow A$, luego $P(A_n) \downarrow P(A)$.
		\item Si $A_n \in \mathcal{A}$ y $A_n \uparrow \Omega$, luego $P(A_n) \uparrow 1$.
		\item Si $A_n \in \mathcal{A}$ y $A_n \uparrow A$, luego $P(A_n) \uparrow P(A)$.
	\end{itemize}

	Más aún, si $P$ es una medida de probabilidad, y dado $\left\{ A_n \right\}$ sucesión de eventos que converge a $A$. Entonces $A \in \mathcal{A}$ y $\lim_{n \rightarrow \infty} P(A_n) = P(A)$ 

\end{theorem}


Finalmente, damos el concepto de sub-$\sigma$-álgebra.

\begin{boxDef}
	Sea $(\Omega, \mathcal{A}, P)$ un espacio de probabilidad. Decimos que $\mathcal{T}$ es una \textbf{sub-}$\sigma$\textbf{-álgebra} si $\mathcal{T} \subseteq \mathcal{A}$ y $\mathcal{T}$ es $\sigma$-álgebra de $\Omega$
\end{boxDef}


% ¿Colocar teorema de la clase monótona?




















% ========================================
%================ SECCIÓN 1.2 Variables aleatorias.
% ========================================

% AÑADIR VARIABLES ALEATORIAS DISCRETAS Y CONTINUAS

\subsection{Variables aleatorias.}

En esta sección, tommaos a $(\Omega, \mathcal{A}, P)$ un espacio abstracto, donde $\Omega$ no es necesariamente contable.

\begin{boxDef}
	Sean $(E, \mathcal{E})$ y $(F, \mathcal{F})$ dos espacios medibles (No necesariamente tienen una medida de probabilidad). Una función $X: E \rightarrow F$ es una \textbf{función medible} si $X^{-1}(\Lambda) \in \mathcal{E}$ para todo $\Lambda \in \mathcal{F}$.\\

	Si $(E, \mathcal{E}, P)$ es un espacio de probabilidad, $X$ posee el nombre de \textbf{variable aleatoria}.
\end{boxDef}

Nuevamente, tenemos varias propiedades para las funciones medibles, que enunciaremos acá, sin la demostración respectiva. Para esto, consulte, PROTTER.

\begin{coro}
	Sea $(E, \mathcal{E})$ un espacio medible aleatorio, y $(\mathbb{R}, \mathcal{B})$. Sea $X, X_n: E \rightarrow \mathbb{R}$ funciones:

	\begin{itemize}
		\item X es medible si y sólo si $\left\{ X \leq a \right\} = X^{-1}( (-\infty, a] ) \in \mathcal{E}$, para todo $a \in \mathbb{R}$.
		\item Si cada $X_n$ es medible, luego $\sup X_n$, $\inf X_n$, $\limsup X_n$ y $\liminf X_n$ son medibles.
		\item Si cada $X_n$ es medible, y $\left\{X_n\right\}$ converge puntualmente a $X$, luego $X$ es medible. 
	\end{itemize}

\end{coro}

\begin{theorem} 
	Sea $X$ medible de $(E, \mathcal{E})$ en $(F, \mathcal{F})$, y $Y$ medible de $(F, \mathcal{F})$ en $(G, \mathcal{G})$. Entonces, $Y \circ X$ es medible de $(E, \mathcal{E})$ en $(G, \mathcal{G})$.
\end{theorem}

\begin{theorem}
	Sean $(E, \mathcal{U})$ y $(F, \mathcal{V})$ espacios topológicos, y $\mathcal{E}$, $\mathcal{F}$ sus $\sigma$-álgebras de Borel (generada por los abiertos), respectivamente. Entonces, cada función continua $X: E \rightarrow F$ es medible (O también llamada, \textit{función boreliana}).
\end{theorem}

Recuerde que, \textit{la función indicadora}, $f(x) = 1_A (x)$ se define como:

\[
	1_A (x) = \left\{  \begin{array}{lc}
		0 & x \in A \\
		1 & x \notin A
	\end{array} \right\}
\]

\begin{theorem}
	Sea $(F, \mathcal{F}) = (\mathbb{R}, \mathcal{B})$ y $(E, \mathcal{E})$ un espacio medible.

	\begin{itemize}
		\item Función indicadora $1_A$ en $E$ es medible si y sólo sí $A \in \mathcal{E}$
		\item Si $X_1, \cdots, X_n$ son funciones medibles de $(E, \mathcal{E})$ en $(\mathbb{R}, \mathcal{B})$, y si $f$ es borel en $\mathbb{R}^n$, luego $f(X_1, \cdots, X_n)$.
		\item Si $X, Y$ son medibles, luego $X + Y$, $XY$, $\max(X,Y)$, $\min{X,Y}$ y $X/Y$ con $Y \neq 0$ son medibles.
	\end{itemize}

\end{theorem}

Recordemos, para $X$ una variable aleatoria, será una función entre los espacios medibles $(\Omega, \mathcal{A})$ y $(E, \mathcal{E})$. Si dotamos al primer espacio de una probabilidad, $P$, de forma canónica podemos dotar al segundo espacio, de una medida de probabilidad, según $X$.

\begin{boxDef}
	Si $X$ es una variable aleatoria entre $(\Omega, \mathcal{A}, P)$, con valores en $(E, \mathcal{E})$, la \textbf{distribución} (O \textbf{medida de distribución}) de $X$, está definida por:

	\[
		P^{X} (B) = P(X^{-1} (B)) =  P(\{ \omega : X(\omega) \in B \}) = P(X \in B)
	\] 

	para todo $B \in \mathcal{E}$. 
\end{boxDef}

	Como la inversa se comporta bien bajo uniones e intersecciones, no es muy dificil probar que:

\begin{theorem}
	La distribución de $X$ es una medida de probabilidad en $(E, \mathcal{E})$
\end{theorem}

	Si $X$ es una variable aleatoria en $\mathbb{R}$, $P^{X}$ es una probabilidad en los reales, caracterizada por la función:

	\[
		F_X (x) = P^{X} ( (-\infty, x] ) = P(X \leq x)
	\]

	por el hecho, que los elementos en los borelianos, $\mathcal{B}$, pueden ser generador por elementos de la forma $(-\infty, x]$. $F_X (x)$ se conoce como \textbf{función de distribución cumulativa}.




















% ========================================
%================ SECCIÓN 1.3 Valor esperado. Integración bajo el signo de la integral.
% ========================================


\subsection{Integración respecto a medida de probabilidad. Valor esperado.}

Dada una variable aleatoria, en un espacio de probabilidad $(\Omega, \mathcal{A}, P)$, podríamos determinar un valor esperado, un promedio ponderado según la probabilidad, la imagen que se espera que tenga la variable aleatoria. \\

Para una variable aleatoria discreta, tenemos la definición:

% AGREGAR DEFINICIÓN PARA V.A DISCRETA

Ahora, queremos hallar el valor esperado para variables aleatorias en general. Consideramos algunos casos especiales inicialmente:

\begin{boxDef}
	Una variable aleatoria $X$ es \textbf{simple} si su imagen es un conjunto finito, por ende, para una familia de conjuntos disyuntos medibles, $ \left\{ A_i  \right\} \subset \mathcal{A}$, y constantes, $a_i \in \mathbb{R}$, para $1 \leq i \leq n$, veremos que la variable aleatoria tiene la forma:

	\[
		X = \sum_{i = 1}^n a_i 1_{A_i}
	\]

	Para $X$ variable aleatoria simple, podemos definir su \textbf{integral respecto a $P$} o \textbf{valor esperado} como:

	\[
		\mathbb{E}[X] = \sum_{i = 1}^n a_i P(A_i)
	\]
	o también denotado por $\int X dP$.

\end{boxDef}

Ahora, deseamos extender la definición para funciones más generales. Para esto, tendremos en cuenta los siguientes resultados:

\begin{theorem}
	Para cada variable aleatoria positiva $X$, existe una sucesión de variables aleatorias simples $\left\{ A_n \right\}_{n \geq 1}$ tal que $X_n$ tiende a $X$ de forma creciente, para $n \rightarrow \infty$ 
\end{theorem}

\textbf{Demostración:} Podemos tomar la sucesión:

\[
	X_n (\omega) = \left\{ \begin{matrix}
		k 2^{-n} & \text{si } k 2^{-n} \leq X(\omega) < (k+1) 2^{-n} \text{ y } 0 \leq k \leq n 2^n - 1 \\
		n & \text{si } X(\omega) \geq n
	\end{matrix}
	 \right.
\]

AÑADIR UNA GRAFICA

\begin{flushright}
	$\Box$
\end{flushright}


\begin{theorem}
	Sea $X$ una variable aleatoria positiva. Si $\left\{ X_n \right\}$ es sucesión de variables aleatorias simples que tienden de forma creciente a $X$, entonces $\mathbb{E}[X_n]$ tiende a $\mathbb{E}[X]$
\end{theorem}

Primero, podemos definir el valor esperado para variables aleatorias en positivas, esto es, que toma valores en $[0, \infty )$, como:

\[
	\int X dP = \mathbb{E}[X] = \sup \left\{ \mathbb{E}[Y] : Y \text{ es función simple con } 0 \leq Y \leq X \right\}
\]

De este modo, podemos definir:

\begin{boxDef}
	Sea $X^+ = \max (X, 0)$ y $X^- = -\min (X, 0)$. Una variable aleatoria $X$ es \textbf{integrable} si $\mathbb{E}[X^+] < \infty$ y $\mathbb{E}[X^-] < \infty$. En este caso, el \textbf{valor esperado} de $X$ se define como:

	\[
		\int X dP = \mathbb{E}[X] = \int X^+ dP + \int X^- dP = \mathbb{E}[X^+] + \mathbb{E}[X^-]
	\] 

	Tenemos que $\mathcal{L}^1$ o $\mathcal{L}^1 (\Omega, \mathcal{A}, P)$, es el conjunto de variables aleatorias que son integrables. \\ 

	% Admite valor esperado?

\end{boxDef}

Ya estamos listos para enunciar varias propiedades importantes de las variables aleatorias.

\begin{theorem}
	\begin{itemize}
		\item $\mathcal{L}^1$ es espacio vectorial, donde $\mathbb{E}$ es operador lineal, y para $X \in \mathcal{L}^1$ tal que $X \geq 0$, luego $\mathbb{E}[X] \geq 0$. Más aún, para $X \leq Y$, tenemos que $\mathbb{E}[X] \leq \mathbb{E}[Y]$.
		\item $X \in \mathcal{L}^1$ si y sólo si $| X | \in \mathcal{L}^1$.
		\item $\left\lvert \mathbb{E}[X] \right\rvert \leq \mathbb{E}[ \left\lvert X \right\rvert ]$. Mas aún, cualquier variable aleatoria acotada es integrable.
		\item Si $X = Y$ \textit{casi siempre} (Esto es, que $P(X = Y) = P(\left\{ \omega : X(\omega) = Y(\omega) \right\}) = 1$), entonces, $\mathbb{E}[X] = \mathbb{E}[Y]$. 
	\end{itemize}	

\end{theorem}

\begin{theorem}[Teorema de la convergencia monótona.]
	Si las variables aleatorias $X_n$ son positivas y tienden de forma creciente \textit{casi siempre} a X, luego $\lim_{n \rightarrow \infty} \mathbb{E}[X_n] = \mathbb{E}[X]$.
\end{theorem}

% ¿Esto está bien?
En este caso, $X_n$ tienden de forma creciente \textit{casi siempre} a X, si \\$P( \left\{ \omega : \lim_{n \rightarrow \infty } X_n (w) = X_n \right\} ) = 1$.

\begin{lema}[Lema de Fatou]
	Si las variables aleatorias $X_n$ satisfacen $X_n \geq Y$ \textit{casi siempre} ( $P( X_n \leq Y ) = P( \left\{ \omega : X_n(\omega) \leq Y(\omega) \right\}) = 1$ ) con $Y \in \mathcal{L}^1$, para todo $n$, entonces:

	\[
		\mathbb{E}\left[\liminf_{n \rightarrow \infty} X_n\right] \leq \liminf_{n \rightarrow \infty} \mathbb{E}[X_n]
 	\]

 	o se puede escribir como:

 	\[
 		\int_{\Omega} \liminf_{n \rightarrow \infty} X_n \leq \liminf_{n \rightarrow \infty} \int_{\Omega}  X_n
 	\]

 	En particular, si $X_n \leq 0$ \textit{casi siempre} para todo $n$, entonces se cumple la desigualdad.

\end{lema}

\begin{theorem}[Teorema de la convergencia dominada de Lebesgue]
	Si las variables aleatorias $X_n$ convergen \textit{casi siempre} a $X$ y si $\lvert X_n \rvert \leq Y$ \textit{casi siempre} para $Y \in \mathcal{L}^1$, para todo $n$, entonces, $X_n, X \in \mathcal{L}^1$, y:

	\[
		\lim_{n \rightarrow \infty } \mathbb{E}[X_n] = \mathbb{E}[X]
	\] 

	o

	\[
		\lim_{n \rightarrow \infty } \int_{\Omega} X_n = \int_{\Omega} X_n
	\]
\end{theorem}

Para consultar las pruebas, sugerimos consultar \cite{Probability_Essentials}. Ahora, estos teoremas poderosos, van a traer una serie de consecuencias, que serán útiles en la práctica. Enunciamos sin demostración.

\begin{theorem}
	Sea $X_n$ una sucesión de variables aleatorias.

	\begin{itemize}
		\item Si para todo $n$, $X_n$ es positiva, entonces:

		\[
			\mathbb{E} \left[ \sum_{n = 1}^{\infty} X_n  \right] =  \sum_{n = 1}^{\infty} \mathbb{E}[X_n]
		\]
		o

		\[
			\int_{\Omega} \sum_{n = 1}^{\infty} X_n  dP  =  \sum_{n = 1}^{\infty} \int_{\Omega} X_n dP
		\]

		\item Si $\sum_{n = 1}^{\infty} \mathbb{E}[ \lvert X_n \rvert ] < \infty$, luego $\sum_{n = 1}^{\infty} X_n$ converge \textit{casi siempre} y la suma de esta serie es integrable. 
	\end{itemize}
\end{theorem}

Antes de enunciar más propiedades, definimos los espacios $\mathcal{L}^p$.

\begin{boxDef}
	Para $1 < p < \infty$, definimos $\mathcal{L}^p$ el espacio de variables aleatorias tal que $\lvert X \rvert^p \in \mathcal{L}^1$.
\end{boxDef}


\begin{theorem}
	\begin{itemize}
		\item Si $X, Y \in \mathcal{L}^2$, entonces $XY \in \mathcal{L}^1$ y se cumple la desigualdad de \textit{Cauchy-Schwarz}:

		\[
			\lvert \mathbb{E}[XY] \rvert \leq \sqrt{ \mathbb{E}[X^2] \mathbb{E}[Y^2] }
		\] 
		\item $\mathcal{L}^2 \subset \mathcal{L}^1$. Si, $X \in \mathcal{L}^2$, luego $\left(\mathcal{E}[X] \right)^2 \leq \mathbb{E}[X^2]$.

		\item $\mathcal{L}^2$ es un espacio vectorial.
	\end{itemize}	
\end{theorem}

El siguiente resultado, permite calcular el valor esperado de cualquier función medible de una variable aleatoria.
	
\begin{theorem}[Regla del valor esperado.]
	Sea $X$ una variable aleatoria en $(\Omega, \mathcal{A}, P)$, con valores en $(E, \mathcal{E})$ y distribución $P^X$. Sea $h: (E, \mathcal{E}) \rightarrow (\mathbb{R}, \mathcal{B})$ una función medible.

	\begin{itemize}
		\item $h(X) \in \mathcal{L}^1 (\Omega, \mathcal{A}, P)$ si y sólo si $h \in \mathcal{L}^1 (E, \mathcal{E}, P^X )$.
		\item Si, $h$ es positiva, o se tienen las condiciones del inciso anterior, entonces:

		\[
			\mathbb{E}[h(X)] = \int_{\Omega} h(x) P^X(dx)
		\] 
	\end{itemize}

\end{theorem}

Finalmente, definimos varianza y mostramos una desigualdad conocida y bastante útil.

\begin{boxDef}
	Si $X \in \mathcal{L}^2$, la \textbf{varianza} de $X$, denotada por $\sigma_X^2$, está dada por:

	\[
		\sigma_X^2 = \mathbb{E}[ (X - \mathbb{E}[X])^2 ]
	\] 
	También llamado \textbf{segundo momento alrededor de la media} $\mu_2$.
\end{boxDef}


\begin{theorem}[Desigualdad de Chebyshev - Bienaymé]
	\[ P( \lvert X\rvert \geq a ) \leq \frac{ \mathbb{E}[X^2] }{ \sigma^2 } \]
\end{theorem}
















% ========================================
%================ SECCIÓN 1?? Probabilidad Condicional.
% ========================================


% \subsection{subsection name} 




















% ========================================
%================ SECCIÓN 1.4 Variables aleatorias independientes
% ========================================

\subsection{Variables aleatorias independientes.}	

Al tener dos variables aleatorias independientes, nos dará varias propiedades, por ejemplo, al tener la esperanza del producto de esas dos variables. De igual forma, vamos a definir $\sigma$-álgebras en $\mathbb{R}^n$.

\begin{boxDef}
	Dado $(\Omega, \mathcal{A}, P)$ un espacio de probabilidad. Dados eventos $A, B \in \mathcal{A}$, definimos la \textbf{probabilidad condicional} de $B$ dado $A$, como:

	\[
		P(B \vert A) = \frac{P(A \cap B)}{P(A)}
	\]

	siempre que $P(B) > 0$.

\end{boxDef}

De manera intuitiva, podemos ver que si $A$ y $B$ son dos eventos, tal que la ocurrencia de uno, no afecta a otro, o dicho de otra forma, son \textit{independientes}, entonces, sería razonable pensar que:

\[
	P(B \vert A) = P(B)
\]

porque el hecho que el evento $A$ ocurra, no afectará en nada a $B$. Formalizando, damos la siguiente definición:

\begin{boxDef}

	Dado $(\Omega, \mathcal{A}, P)$ y $\left\{ A_i \right\}_{i \in I}$ una colección (a lo más contable) de conjuntos medibles, que pertenecen a $\mathcal{A}$ (También llamados \textit{eventos}). Se dice que la colección es \textbf{colección independiente}, o \textbf{mutuamente independiente}, si dado $J \subset I$ conjunto finito de índices, se cumple que:

	\[
		P \left( \cap_{j \in J} A_j \right) = \prod_{j \in J} P(A_j)
	\].

	La colección es \textbf{independiente de a parejas}, si para todo $i, j \in I$, se tiene que $P(A_j \cap A_i) = P(A_j) P(A_i)$. 
	
\end{boxDef}

Tenga en cuenta, que si la colección $\left\{ A_i \right\}_{i \in I}$ es mutuamente independiente, entonces es independiente de a parejas. Sin embargo, la recíproca no se tiene.\\

Damos algunas propiedades y teoremas importantes acerca de eventos independientes.

\begin{theorem}
	Si $A, B$ son independientes, entonces:

	\begin{itemize}
		\item $A$, $B^c$
		\item $A^c$, $B$
		\item $A^c$, $B^c$	
	\end{itemize}

	son también independientes.

\end{theorem}


\begin{theorem}[Ley de la probabilidad total.]
	Dado $(\Omega, \mathcal{A}, P)$ un espacio de probabilidad. Sea $\left\{ E_n \right\}_{n \geq 1}$ una partición a lo más contable de $\Omega$. Luego, para un evento $A \in \mathcal{A}$, se cumple:

	\[
		P(A) = \sum_{n} P(A \vert E_n) P(E_n)
	\]

\end{theorem}

\begin{theorem}[Teorema de Bayes.]
	Dado $(\Omega, \mathcal{A}, P)$ un espacio de probabilidad. Sea $\left\{ E_n \right\}_{n \geq 1}$ una partición a lo más contable de $\Omega$, y sea $P(A) > 0$. Entonces:

	\[
		P(E_n \vert A) = \frac{ P(A \vert E_n) P(E_n) }{\sum_m P(A \vert E_m)P(E_m)}
	\]

\end{theorem}

Ahora, podemos generalizar el concepto de independencia a $\sigma$-álgebras, e inclusive, a variables aleatorias.

\begin{boxDef}
	Sea $(\Omega, \mathcal{A}, P)$ un espacio de probabilidad.
	\begin{itemize}
		\item Dadas sub-$\sigma$-álgebras $\left\{ A_i \right\}_{i \in I}$ de $\mathcal{A}$. Decimos que esta colección es \textbf{independiente} si para todo $J \subseteq I$ con $J$ finito, y todo $A_i \in \mathcal{A}_i$, se cumple que:

		\[
			P\left( \cap_{j \in J} A_j \right) = \prod_{j \in J} P(A_j)	
		\]
		En este caso, hablamos de \textbf{independencia de } $\sigma$ \textbf{-álgebras}. 

		\item Sea $\left\{ X_i \right\}_{i \in I}$ un conjunto de variables aleatorias en el espacio de probabilidad dado, tal que la imagen de $X_i$ es $(E_i, \mathcal{E_i})$. Decimos que las variables aleatorias son \textbf{independientes} si $\sigma (X_i) = X_i^{-1}(\mathcal{E_i})$ (Esto es, las $\sigma$-álgebras generadas por $X_i$) son independientes.
	\end{itemize}

\end{boxDef}

Enunciamos algunas propiedades para $X$ y $Y$ variables aleatorias independientes. De forma canónica, se puede extender el enunciado a un número a lo más contable de variables aleatorias independientes, $\left\{ X_i \right\}_{i \in I}$.

\begin{theorem}
	Sea $X, Y$ variables aleatorias cuya imagen son los espacios $(E, \mathcal{E})$ y $(F, \mathcal{F})$, respectivamente. $X$ y $Y$ son independientes si y sólo sí, se tiene algunas de las siguientes condiciones:

	\begin{itemize}
		\item $P(X \in A, Y \in B) = P(X \in A)P(Y \in B)$ para todo $A \in \mathcal{E}$ y $B \in \mathcal{F}$.
		\item $P(X \in A, Y \in B) = P(X \in A)P(Y \in B)$, para todo $A \in \mathcal{C}$, $B \in \mathcal{D}$ donde $\mathcal{C}, \mathcal{D}$ son clases de conjuntos cerrados bajo intersecciones finitas, tal que $\sigma(\mathcal{C}) = \mathcal{E}$ y $\sigma( \mathcal{D} ) = \mathcal{F}$
		\item Para $f, g$ funciones medibles, $f(X)$ y $g(X)$ son independientes.
		\item Para $f, g$ funciones medibles positivas, o medibles acotadas, $\mathbb{E}[ f(X)g(Y) ] = \mathbb{E}[f(X)] \mathbb{E}[g(Y)]$.
		\item Sean $E, F$ espacios métricos, y $\mathcal{E}, \mathcal{F}$ sus $\sigma$-álgebras de Borel. Entonces, $\mathbb{E}[ f(X)g(Y) ] = \mathbb{E}[f(X)] \mathbb{E}[g(Y)]$ para todas $f, g$ funciones acotadas y continuas.
	\end{itemize}

\end{theorem}

En este punto, vemos que estamos comenzando a tomar conjuntos de dos o más variables aleatorias. Sería deseable hablar de una noción de \textit{conjuntamente medible}. Sean $(E, \mathcal{E})$ y $(F, \mathcal{F})$ espacios medibles. En general, $\mathcal{E} \times \mathcal{F} = \left\{ A \subseteq E \times F | A = \Lambda \times \Gamma, \Lambda \in \mathcal{E}, \Gamma \in \mathcal{F} \right\}$ no será una $\sigma$-álgebra, por ejemplo, si tomamos el producto $\mathcal{B}(\mathbb{R}) \times \mathcal{B}(\mathbb{R})$ (Producto de los conjuntos de Borel en $\mathbb{R}$), es tentador pensar que tal producto es $\sigma$-álgebra de $\mathbb{R}^2$, sin embargo, note que el elemento $[0, 1] \times [0,1] \cup [-1, -1/2] \times [0, 1]$ debe estar en la $\sigma$-álgebra de $\mathbb{R}^2$, pero no está en $\mathcal{B}(\mathbb{R}) \times \mathcal{B}(\mathbb{R})$, falla la estabilidad bajo uniones. \\

Por tanto, denotaremos a:
\[
	\mathcal{E} \otimes \mathcal{F} = \sigma(\mathcal{E} \times \mathcal{F})
\]
como la menor $\sigma$-álgebra que contiene a $\mathcal{E} \times \mathcal{F}$. Tal cuál como las anteriores definiciones, enunciamos algunas propiedades y teoremas que serán de utilidad.

\begin{theorem}
	Sea $f: (E\times F, \mathcal{E} \otimes \mathcal{F}) \rightarrow (\mathbb{R}, \mathcal{R})$ función medible. Entonces, las secciones $y \rightarrow f(x, y)$ (Para todo $x \in E$) y $x \rightarrow f(x, y)$ (Para todo $y \in F$) son, respectivamente, $\mathcal{F}$-medible y $\mathcal{E}$-medible.
\end{theorem}

\begin{theorem}[Tonelli-Fubini]
	Sea $(E, \mathcal{E}, P)$ y $(F, \mathcal{F}), Q$ espacios de probabilidad. 

	\begin{itemize}
		\item Sea $R(A \times B) = P(A)Q(B)$, para $A \in \mathcal{E}$ y $B \in \mathcal{F}$. Entonces, $R$ se extiende de forma unívoca a una probabilidad en $(E \times F, \mathcal{E} \otimes \mathcal{F})$, denotada por $P \otimes Q$.

		\item Cada función $f$ que es $\mathcal{E} \otimes \mathcal{F}$-medible, positiva o integrable, respecto a $P \otimes Q$, tenemos que $x \rightarrow \int f(x,y) Q(dy)$ es $\mathcal{E}$-medible, $y \rightarrow \int f(x,y) P(dx)$ es $\mathcal{F}$-medible. Además:

		\[
			\int f dP\otimes Q = \int \left\{ \int f(x,y) Q(dy) \right\} P(dx) = \int \left\{ \int f(x,y) P(dx) \right\} Q(dy)
		\]

	\end{itemize}

\end{theorem}


Antes de acabar esta sección, vamos a ver dos teoremas importantes en probabilidad. Primero damos una definiciones:

\begin{boxDef}
	\begin{itemize}
		\item Sea $A_n$ una sucesión de eventos en $\mathcal{A}$. Definimos:

		\[
			\limsup_{n \rightarrow \infty } A_n = \cap_{n = 1}^{\infty} (\cup_{m \geq n}) A_m = \lim_{n \rightarrow \infty} (\cup_{m \geq n} A_m)
		\]
		De manera probabilística, podemos interpretar este evento como:
		\[
			\limsup_{n \rightarrow \infty} A_n = A_n \text{ ocurre \textbf{infinitamente seguido}}
		\]
		o del inglés, \textit{infinitely often (i.o)}. Esto es, que el evento $A_n$ ocurre para un número infinito de $n$. Podemos escribir:
		\[
			\limsup_{n \rightarrow \infty} A_n = \left\{ A_n \text{ i.o } \right\}
		\]

		\item Sean $X_n$ variables aleatorias definidas en $(\Omega, \mathcal{A}, P)$. Defina las $\sigma$-álgebras:

		\begin{align*}
			B_n &= \sigma(X_n)\\
			C_n &= \sigma(\cup_{p \geq n} B_n)\\
			C_{\infty} = \cap_{n=1}^{\infty} C_n
		\end{align*}

		$C_{\infty}$ es la $\sigma$-\textbf{álgebra cola}.

	\end{itemize}
\end{boxDef}


\begin{theorem}[Lema de Borel-Cantelli.]
	Sea $A_n$ una sucesión de eventos en $(\Omega, \mathcal{A}, P)$.

	\begin{itemize}
		\item Si $\sum_{n = 1}^{\infty} P(A_n) < \infty$, luego $P(A \text{i.o}) = 0$.
		\item Si $P(A_n \text{i.o}) = 0$ y si los eventos $A_n$ son mutuamente independientes, entonces $\sum_{n = 1}^{\infty} P(A_n) < \infty$. 
	\end{itemize}

\end{theorem}


\begin{theorem}[Ley cero-uno de Kolmogorov.]
	Sea $X_n$ una sucesión de variables aleatorias independientes, definidas en $(\Omega, \mathcal{A, P})$, y sea $C_{\infty}$ la $\sigma$-álgebra cola correspondiente. Si $C \in C_{\infty}$, entonces $P(C) = 0$ o $P(C) = 1$.
\end{theorem}






% ========================================
%================ SECCIÓN 1.5 Distribuciones en R, R^n. Variables multivariadas o Gaussianas.
% ========================================


\subsection{Distribuciones en $\mathbb{R}^n$ y variables aleatorias Gaussianas.}

% Colocar acerca de la función característica.














% ========================================
%================ SECCIÓN 1.6 Convergencia de variables aleatorias.
% ========================================


\subsection{Convergencia de variables aleatorias.}





% ========================================
%================ SECCIÓN 1.7 Esperanza Condicional
% ========================================

\subsection{Esperanza Condicional.}

Para $X, Y$ variables aleatorias (Con $Y$ tomando valores de $\mathbb{R}$ y $X$ toma valores a lo sumo contables), ya sabemos calcular el valor de $P(Y \vert X = i)$, esto es, la probabilidad condicional de $Y$ dado $X = i$. Deseamos extender este concepto, para poder calcular el valor esperado de la variable aleatoria $Y$, dado que $X = i$, esto es, una \textit{esperanza condicional.}

\begin{boxDef}
 	Dado $X$ que toma valores en $\left\{ x_1, \cdots, x_n, \cdots \right\}$ (Conjunto a lo sumo contable), y $Y$ una variable aleatoria. Si $P(X = x_j) > 0$, entonces la \textbf{esperanza condicional de $Y$ dado $\left\{ X = x_j \right\}$} está definida por:

 	\[
 		\mathbb{E} [Y \vert X = x_j] = \mathbb{E}_Q [Y] = \int Y dQ
 	\]

 	tal que $Q(\Lambda) = P(\Lambda \vert X = x_j)$, y dado que $\mathbb{E}_Q [ \lvert Y \rvert] < \infty$.
\end{boxDef} 

Una forma clásica de calcular esta esperanza condicional, con $Y$ tomando valores de un conjunto a lo más contable, está enunciada en este teorema, que es consecuencia de la definición:

\begin{theorem}
	Asuma las condiciones de la definición anterior. Además, si $Y$ tiene valores contables $\left\{ y_1, \cdots, y_n, \cdots \right\}$ y si $P(X = x_j) > 0$, entonces:

	\[
		\mathbb{E}[Y \vert X = x_j] = \sum_{k = 1}^{\infty} y_k P(Y = y_k \vert X = x_j)
	\]
	dado que la serie converge absolutamente.
\end{theorem}

Sin embargo, no todas las variables aleatorias tomarán valores de un conjunto a lo más contable, deseamos extender la definición a variables aleatorias más generales. Primero, podemos definir la esperanza condicional, entre dos variables aleatorias. 

\begin{boxDef}
	Sea:

	\[
		f(x) = \left\{  
		\begin{matrix}
			\mathbb{E}[Y \vert X = x] & \text{ si } P(X = x) > 0 \\
			\text{Otro valor} & \text{ si } P(X = x) = 0
		\end{matrix} \right.
	\]

	Dado $X$ con valores contables, y $Y$ una variable aleatoria con valores en $\mathbb{R}$. La \textbf{esperanza condicional de $Y$ dado $X$} está definida por:

	\[
		\mathbb{E}[Y \vert X] = f(Y)
	\]
\end{boxDef}

Note que la definición está dada por eventos que ocurren \textit{casi siempre (a.s)}, es decir, salvo en elementos, donde la probabilidad sea $0$. Ahora, si $X$ toma valores reales, en general los eventos $\{ X = x_j\}$ tendrán probabilidad $0$ y el enfoque dado no funciona. \\

Sin embargo, lo que se realizó fue hallar una función $f$ auxiliar, para hallar la esperanza condicional, y este será el enfoque que se tomará para el caso en general. Para cumplir el objetivo, se usará el siguiente teorema.

\begin{theorem}[Lema de Doob-Dynkin.]
	Sea $X$ una variable aleatoria con valores en $\mathbb{R}^n$, y $Y$ una variable aleatoria con valores en $\mathbb{R}$. $Y$ es medible con respecto a $\sigma (X)$ (La $\sigma$-álgebra generada por $X$) si y sólo si existe una función $f: \mathbb{R}^n \rightarrow \mathbb{R}$ que sea Borel-medible tal que $Y = f(X)$.
\end{theorem}

% ¿Colocar ejemplos?


Sea $(\Omega, \mathcal{A}, P)$ un espacio de probabilidad, y $X: \Omega \rightarrow \mathbb{R}^n$ una variable aleatoria. Recuerde que, $\mathcal{L}^2$ es el espacio de los \textit{cuadrado-integrables}, esto es, que para $Y \in \mathcal{L}^2$, $\mathbb{E}[Y^2] < \infty$ (O $\int_{\Omega} Y^2 dP < \infty $ ). Como $\mathcal{L}^2 (\Omega, \mathcal{A}, P)$ es un \textit{espacio de Hilbert}, entonces se puede definir un producto interno en este espacio:

\[
	\langle Y, Z \rangle = \int_{\Omega} Y Z dP = \mathbb{E}[YZ]
\]
Como $\sigma(X) \subset \mathcal{A}$, entonces $(\Omega, \sigma(X), P)$ es también un subespacio de Hilbert. Dado estos conceptos, se procede a generalizar la esperanza condicional.

\begin{boxDef}
	Sea $Y \in \mathcal{L}^2 (\Omega, \mathcal{A}, P)$. La \textbf{esperanza condicional de $Y$ dado $X$} es el único $\hat{Y} \in \mathcal{L}^2 (\Omega, \sigma(X), P)$ tal que:
	\[
		\mathbb{E}[\hat{Y}X] = \mathbb{E}[YZ]
	\]
	para todo $Z \in \mathcal{L}^2 (\Omega, \sigma(X), P)$, se denota como $\mathbb{E}[Y \vert X] = \hat{Y}$.
\end{boxDef}

Note que la esperanza condicional de $Y$ dado $X$, será la proyección de $Y$ en el subespacio de Hilbert $\mathcal{L}^2 (\Omega, \sigma(X), P)$. Para más detalles de análisis funcional, consulte el apéndice.

Como $\hat{Y}$ es $\sigma (X)$-medible, por el lema de Doob-Dynkin, existe una función $f$ Borel medible tal que:

\[
	\mathbb{E}[Y \vert X] = f(X)
\]

Entonces, se tiene una expresión alternativa para el teorema de Doob-Dynkin; para toda función $g$ Borel-medible tal que $g(X) \in \mathcal{L}^2$:

\[
	\mathbb{E}[f(X) g(X)] = \mathbb{E}[Y g(X)]
\]

Ahora, se puede definir la esperanza condicional respecto a una $\sigma$-álgebra.

\begin{boxDef}
	Sea $Y \in \mathcal{L}^2 (\Omega, \mathcal{A}, P)$ y $\mathcal{G}$ una sub-$\sigma$-álgebra de $\mathcal{A}$. Definimos la \textbf{esperanza condicional de $Y$ respecto a $\mathcal{G}$} como el único elemento $\mathbb{E}[Y \vert \mathcal{G}] \in \mathcal{L}^2 (\Omega, \mathcal{G}, P)$ tal que:

	\[
		\mathbb{E}[Y Z] = \mathbb{E}[ \mathbb{E}[Y \vert \mathcal{G}] Z ]
	\] 
	para todo $Z \in \mathcal{L}^2 (\Omega, \mathcal{G}, P)$. También podemos escribir como:

	\[
		\mathbb{E}[Y \vert \mathcal{G}] = \int_{\Lambda} Y dP
	\]
	para todo $\Lambda in \mathcal{G}$.
\end{boxDef}

Note que, $\mathbb{E}[Y \vert \mathcal{G}]$ se puede ver como la proyección de $Y$ sobre el subespacio de Hilbert $(\Omega, \mathcal{G}, P)$. \\

Como dato adicional, es importante recalcar que la esperanza condicional es un elemento de $\mathcal{L}^2$, y es una \textit{clase de equivalencia} de alguna variable aleatoria. Por ende, relaciones del tipo $\mathbb{E}[Y \vert \mathcal{G}] \geq 0$ o $\mathbb{E}[Y \vert \mathcal{G}] = Z$ se sobreentienden como relaciones que se cumplen en \textit{casi siempre} o en \textit{casi todo sitio} (Esto es, se preserva la igualdad salvo en conjuntos nulos o de medida cero).\\

Al igual que el operador $\mathbb{E}$ cumple varias propiedades, también $\mathbb{E}[\cdot \vert  \cdot]$ cumple propiedades similares.

\begin{theorem}[Propiedades de la esperanza condicional.]
	Sea $Y \in \mathcal{L}^2 (\Omega, \mathcal{A}, P)$ y $\mathcal{G}$ una sub-$\sigma$-álgebra de $\mathcal{A}$. Entonces, 

	\begin{itemize}
		\item Si $Y \geq 0$, luego $\mathbb{E}[Y \vert \mathcal{G}] \geq 0$.
		\item Si $\mathcal{G} = \sigma (X)$ para cierta variable aleatoria $X$, entonces existe una función Borel medible $f$ tal que $\mathbb{E}[Y \vert \mathcal{G}] = f(X)$.
		\item $\mathbb{E}[\mathbb{E}[Y \vert \mathcal{G}]] = \mathbb{E}[Y]$.
		\item La función $Y \rightarrow \mathbb{E}[Y \vert \mathcal{G}]$ es lineal.
	\end{itemize}
\end{theorem}


\begin{theorem}
	Sea $Y \in \mathcal{L}^{+}(\Omega, \mathcal{A}, P)$ (El espacio de variables aleatorias no negativas), y sea $\mathcal{G}$ una sub-$\sigma$-álgebra de $\mathcal{A}$. Entonces existe un único elemento $\mathbb{E}[Y \vert \mathcal{G}]$ de $\mathcal{L}^{+}(\Omega, \mathcal{G}, P)$ tal que:

	\[
		\mathbb{E}[Y X] = \mathbb{E}[ \mathbb{E}[Y \vert \mathcal{G}] X ]
	\]
 	
 	para todo $X \in \mathcal{L}^{+}(\Omega, \mathcal{G}, P)$. Más aún, si $0 \leq Y \leq Y'$, luego:

 	\[
 		\mathbb{E}[Y \vert \mathcal{G}] \leq \mathbb{E}[Y' \vert \mathcal{G}],
 	\]
 	es decir, la esperanza condicional es monótona creciente.
\end{theorem}

\begin{theorem}
	Sea $Y \in \mathcal{L}^{+}(\Omega, \mathcal{A}, P)$ y $\mathcal{G}$ una sub-$\sigma$-álgebra de $\mathcal{A}$. Entonces, existe un único elemento $\mathbb{E}[Y \vert \mathcal{G}] \in \mathcal{L}^1 (\Omega, \mathcal{G}, P)$ tal que:

	\[
		\mathbb{E}[Y X] = \mathbb{E}[ \mathbb{E}[Y \in \mathcal{G}] X ]
	\]
	para toda $X$ que es acotada y $\mathcal{G}$-medible. Además, se cumple:

	\begin{itemize}
		\item Si $Y \geq 0$, luego $\mathbb{E}[Y \vert \mathcal{G}] \geq 0$.
		\item $Y \rightarrow \mathbb{E}[Y \vert \mathcal{G}]$ es un mapa lineal. 
	\end{itemize}

\end{theorem}

Note que, se han visto algunas definiciones equivalentes a la esperanza condicional. \\

Ahora, se puede caracterizar la esperanza condicional para diversos casos, como cuando una variable aleatoria es medible respecto a una sub-$\sigma$-álgebra.

\begin{theorem}
	Sea $Y$ una variable aleatoria positiva o integrable en $(\Omega, \mathcal{A},P)$, y sea $\mathcal{G}$ una sub-$\sigma$-álgebra. Entonces, $\mathbb{E}[Y \vert \mathcal{G}] = Y$ si y sólo si $Y$ es $\mathcal{G}$-medible.
\end{theorem}

Al tomar dos variables aleatorias, y colocar condiciones, se pueden obtener resultados interesantes.

\begin{theorem}
	Sea $Y \in \mathcal{L}^1 (\Omega, \mathcal{A}, P)$, y sea $X, Y$ independientes, luego:

	\[
		\mathbb{E}[Y \vert X] = \mathbb{E}[Y]
	\]
\end{theorem}


\begin{theorem}
	Sea $X, Y$ variables aleatorias en $(\Omega, \mathcal{A}, P)$, sea $\mathcal{G}$ una sub-$\sigma$-álgebra de $\mathcal{A}$, y suponga que $X$ es $\mathcal{G}$-medible. Si $X, Y$ y $XY$ son integrables, o si $X,Y$ son positivos, tendremos que:
	$\mathbb{E}[XY \vert \mathcal{G}] = X \mathbb{E}[Y \vert \mathcal{G}]$
\end{theorem}

En la esperanza condicional, también se tendrán los teoremas importantes de convergencia, que se tenían para la esperanza usual.

\begin{theorem}[Teoremas de convergencia para la esperanza condicional.]
	Sea $\left\{ Y_n \right\}_{n \geq 1}$ una sucesión de variables aleatorias en $(\Omega, \mathcal{A}, P)$, y sea $\mathcal{G}$ una sub-$\sigma$-álgebra de $\mathcal{A}$.

	\begin{itemize}
		\item \textbf{(Convergencia monótona).} Si $Y_n \geq 0$, $n \geq 1$ y $Y_n \rightarrow Y$ de forma creciente, luego, \textit{casi siempre} se tiene:

		\[
			\lim_{n \rightarrow \infty} \mathbb{E}[Y_n \vert \mathcal{G}] = \mathbb{E}[Y \vert \mathcal{G}]
		\]

		\item \textbf{(Lema de Fatou).} Si $Y_n \geq 0$, $n \geq 1$, entonces:

		\[
			\mathbb{E}[ \liminf_{n \rightarrow \infty} Y_n \vert \mathcal{G} ] \leq \liminf_{n \rightarrow \infty} \mathbb{E}[Y_n \vert \mathcal{G}]
		\]

		\item \textbf{(Teorema de la convergencia dominada de Lebesgue.)} Si $\lim_{n \rightarrow \infty} Y_n = Y$ \textit{casi siempre}, y $\lvert Y_n \rvert \geq Z$, con $n \geq 1$ para algún $Z \in \mathcal{L}^1 (\Omega, \mathcal{A}, P)$, entonces, \textit{casi siempre}:

		\[
			\lim_{n \rightarrow \infty} \mathbb{E}[Y_n \vert \mathcal{G}] = \mathbb{E}[Y \vert \mathcal{G}]
		\]


	\end{itemize}

\end{theorem}

Se finaliza la sección, con algunas desigualdades importantes que involucran a la esperanza condicional.

\begin{theorem}[Desigualdad de Jensen.]
	Dada $\phi: \mathbb{R} \rightarrow \mathbb{R}$ una función convexa, y sea $X$, $\phi(X)$ variables aleatorias. Entonces, para toda sub-$\sigma$-álgebra, se tiene que:

	\[
		\phi \left( \mathbb{E}[X \vert \mathcal{G}] \right) \leq \mathbb{E}[\phi(X) \vert \mathcal{G} ]
	\]
\end{theorem}

Como consecuencia de la desigualdad de Jensen, se tiene:

\begin{theorem}[Desigualdad de Hölder.]
	Dados $X, Y$ variables aleatorias, tal que $\mathbb{E}[ \lvert X \rvert^p ] \leq \infty$, $\mathbb{E}[ \lvert Y \rvert^q ] \leq \infty$ con $p > 1$, y $\frac{1}{p} + \frac{1}{q} = 1$. Luego:

	\[
		\mathbb{E}[ \lvert XY \rvert ] \leq \mathbb{E}[ \lvert X \rvert^p ]^{\frac{1}{p}} \mathbb{E}[ \lvert Y \rvert^q ]^{\frac{1}{q}}
	\]
\end{theorem}

Y de igual forma, se tiene una consecuencia de la desigualdad de Hölder:

\begin{theorem}[Desigualdad de Minkowski.]
	Dada $X, Y$ variables aleatorias, $1 \leq p < \infty$ con $\mathbb{E}[ \lvert X \rvert^p ] < \infty$ y $\mathbb{E}[ \lvert Y \rvert^p ] < \infty$. Luego:

	\[
		\mathbb{E}[ \lvert X + Y \rvert^p ]^{ \frac{1}{p} } \leq \mathbb{E}[X^p]^{\frac{1}{p}} + \mathbb{E}[Y^p]^{\frac{1}{p}}
	\]
\end{theorem}


% Variables aleatorias. OK

% Medida de probabilidad. OK

% Probabilidad Condicional. ¿?

% Independencia de variables aleatorias. OK

% Integración respecto a medida de probabilidad. OK

% Distribuciones en R^n. Variables aleatorias Gaussianas.

% Convergencia de esta mondá, Ley de los grandes números.

% Esperanza Condicional, OK.

% -> Apéndice L2 y Espacios de Hilbert.

% Sí, Función característica.


























% PROCESOS ESTOCÁSTICOS



% ========================================
%================ SECCIÓN ?. PROCESOS ESTOCÁSTICOS. (CAPÍTULO MOVIMIENTO BROWNIANO)
% ========================================

%\section{Procesos Estocásticos.}















% ========================================
%================ SECCIÓN 2. PRELIMINARES DE INTEGRACIÓN Y ECUACIONES DIFERENCIALES.
% ========================================

\section{Preliminares de Integración y Ecuaciones Diferenciales.}




% INTEGRACIÓN.

% Integración usual RS, Integral de Young. Conceptos de p-variación y $\alpha$-Hölder.

% Ecuaciones Diferenciales Ordinarias. EDO Controladas. ¿EDP?

% Teorema de Picard, Teorema de Peano.