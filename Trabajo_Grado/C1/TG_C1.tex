
\chapter{Preliminares}


En este capítulo, nos dedicaremos a repasar conceptos de teoría de la probabilidad, teoría de integración y ecuaciones diferenciales. 













% ========================================
%================ SECCIÓN 1. PROBABILIDAD
% ========================================










% ========================================
%================ SECCIÓN 1.1 Espacios de probabilidad.
% ========================================



\section{Conceptos de Probabilidad.}

En esta sección, daremos un breve repaso a conceptos esenciales en probabilidad, para poder entender mejor procesos estocásticos, y de igual forma, poder realizar la construcción de la integral de Itô. Para mayor información, puede consultar \cite{Probability_Essentials}, del cuál se basará la gran parte de este capítulo.

\subsection{Espacios de probabilidad.}

Sea $\Omega$ un conjunto abstracto. Denotamos por $2^{\Omega}$ el conjunto de partes de $\Omega$.

\begin{boxDef}
Definimos a $\mathcal{F}$ una $\mathbf{\sigma}$\textbf{-álgebra} de $\Omega$, como un subconjunto de $2^{\Omega}$ que cumple las siguientes propiedades:

	\begin{itemize}
		\item $\emptyset$, $\Omega$ $\in \mathcal{F}$
		\item Si $A \in \mathcal{A}$, luego $A^{c} \in \mathcal{A}$
		\item Dado $\{ A_i \}_{i \in I}$ una sucesión de subconjuntos de $\Omega$ a lo más contable. Luego, si para todo $i \in I$, $A_i \in \mathcal{A}$, entonces $\cup_{i \in I} A_i \in \mathcal{A}$ 
	\end{itemize}

El espacio $\left( \Omega, \mathcal{A} \right)$ se llama \textbf{espacio medible}.

\end{boxDef}



Los elementos en $\mathcal{A}$ se llamarán \textit{eventos}.



\textbf{Ejemplo:}

\begin{itemize}

	\item Para $\Omega$ un conjunto abstracto, $\mathcal{A} = \left\{ \emptyset, \Omega \right\}$ es la $\sigma$-álgebra trivial. 

	\item Sea $A \subset \Omega$, entonces $\sigma(A) = \left\{ \emptyset, A, A^c, \Omega \right\}$ también es una $\sigma$-álgebra, llamada la \textbf{menor} $\mathbb{\sigma}$-\textbf{álgebra} que contiene a $A$, que se genera mediante la intersección de todas las $\sigma$-álgebras que contienen a $A$. 

	\item Para $\Omega = \mathbb{R}$, una $\sigma$-álgebra para este conjunto es la $\sigma$-\textbf{álgebra de Borel}, que se puede generar con intervalos de la forma $(-\infty, a]$ para todo $a \in \mathbb{Q}$. También, es la generada por todos los conjuntos abiertos (O cerrados, o semiabiertos...). Para más información consulte \cite{Measure_Theory_DC} Y \cite{Probability_Essentials}

\end{itemize}

\begin{flushright}
	$\Box$
\end{flushright}


\begin{boxDef}
	Una \textbf{medida de probabilidad} definida en una $\sigma$-álgebra $\mathcal{A}$ de $\Omega$, es una función $P: \mathcal{A} \rightarrow [0,1]$ que cumple:

	\begin{itemize}
		\item $P(\Omega) =  1$\\
		\item Para toda colección contable $\left\{ A_n \right\}_{n \geq 1}$ de elementos en $\mathcal{A}$ que son disyuntos par a par, se tiene:

		\[
			P\left( \cup_{n=1}^{\infty}  \right) = \sum_{n = 1}^{\infty} P\left( A_n \right)
		\]

		Es decir, la función es \textit{contablemente aditiva}. Se llama a $P(A)$ como la \textit{probabilidad del evento A}.

	\end{itemize}

La tripla $(\Omega, \mathcal{A}, P)$ se conoce como \textbf{espacio de probabilidad}.

\end{boxDef}

De forma general, la medida de probabilidad, es un caso específico de una \textit{función de medida}, en este caso, tendremos un \textit{espacio de medida}. Vea COHN.\\

Note que, podemos ver una propiedad más débil que el axioma (2) en la anterior definición. Para toda colección $\left\{  A_k \right\}_{k = 1}^{n}$ \textit{finita}, de disyuntos par a par, si tenemos:

\[
	P\left( \cup_{k=1}^n A_k \right) = \sum_{k = 1}^{n} P(A_k)
\]
entonces la función $P$ es \textbf{aditiva (O finitamente aditiva)}.

Vamos a revisar algunas propiedades de las funciones de probabilidad, sin demostración. Para consultar los detalles, puede consultar PROTTER.

\begin{theorem}
	Sea $(\Omega, \mathcal{A})$ un espacio medible, y $P: \mathcal{A} \rightarrow [0,1]$ una función finitamente aditiva y $P(\Omega) = 1$. Entonces, tenemos las siguientes equivalencias:

	\begin{itemize}
		\item La función es contablemente aditiva.
		\item Si $A_n \in \mathcal{A}$ y $A_n \downarrow \emptyset$, luego $P(A_n) \downarrow 0$.
		\item Si $A_n \in \mathcal{A}$ y $A_n \downarrow A$, luego $P(A_n) \downarrow P(A)$.
		\item Si $A_n \in \mathcal{A}$ y $A_n \uparrow \Omega$, luego $P(A_n) \uparrow 1$.
		\item Si $A_n \in \mathcal{A}$ y $A_n \uparrow A$, luego $P(A_n) \uparrow P(A)$.
	\end{itemize}

	Más aún, si $P$ es una medida de probabilidad, y dado $\left\{ A_n \right\}$ sucesión de eventos que converge a $A$. Entonces $A \in \mathcal{A}$ y $\lim_{n \rightarrow \infty} P(A_n) = P(A)$ 

\end{theorem}


Finalmente, damos el concepto de sub-$\sigma$-álgebra.

\begin{boxDef}
	Sea $(\Omega, \mathcal{A}, P)$ un espacio de probabilidad. Decimos que $\mathcal{T}$ es una \textbf{sub-}$\sigma$\textbf{-álgebra} si $\mathcal{T} \subseteq \mathcal{A}$ y $\mathcal{T}$ es $\sigma$-álgebra de $\Omega$
\end{boxDef}


% ¿Colocar teorema de la clase monótona?




















% ========================================
%================ SECCIÓN 1.2 Variables aleatorias.
% ========================================

% AÑADIR VARIABLES ALEATORIAS DISCRETAS Y CONTINUAS

\subsection{Variables aleatorias.}

En esta sección, tommaos a $(\Omega, \mathcal{A}, P)$ un espacio abstracto, donde $\Omega$ no es necesariamente contable.

\begin{boxDef}
	Sean $(E, \mathcal{E})$ y $(F, \mathcal{F})$ dos espacios medibles (No necesariamente tienen una medida de probabilidad). Una función $X: E \rightarrow F$ es una \textbf{función medible} si $X^{-1}(\Lambda) \in \mathcal{E}$ para todo $\Lambda \in \mathcal{F}$.\\

	Si $(E, \mathcal{E}, P)$ es un espacio de probabilidad, $X$ posee el nombre de \textbf{variable aleatoria}.
\end{boxDef}

Nuevamente, tenemos varias propiedades para las funciones medibles, que enunciaremos acá, sin la demostración respectiva. Para esto, consulte, PROTTER.

\begin{coro}
	Sea $(E, \mathcal{E})$ un espacio medible aleatorio, y $(\mathbb{R}, \mathcal{B})$. Sea $X, X_n: E \rightarrow \mathbb{R}$ funciones:

	\begin{itemize}
		\item X es medible si y sólo si $\left\{ X \leq a \right\} = X^{-1}( (-\infty, a] ) \in \mathcal{E}$, para todo $a \in \mathbb{R}$.
		\item Si cada $X_n$ es medible, luego $\sup X_n$, $\inf X_n$, $\limsup X_n$ y $\liminf X_n$ son medibles.
		\item Si cada $X_n$ es medible, y $\left\{X_n\right\}$ converge puntualmente a $X$, luego $X$ es medible. 
	\end{itemize}

\end{coro}

\begin{theorem} 
	Sea $X$ medible de $(E, \mathcal{E})$ en $(F, \mathcal{F})$, y $Y$ medible de $(F, \mathcal{F})$ en $(G, \mathcal{G})$. Entonces, $Y \circ X$ es medible de $(E, \mathcal{E})$ en $(G, \mathcal{G})$.
\end{theorem}

\begin{theorem}
	Sean $(E, \mathcal{U})$ y $(F, \mathcal{V})$ espacios topológicos, y $\mathcal{E}$, $\mathcal{F}$ sus $\sigma$-álgebras de Borel (generada por los abiertos), respectivamente. Entonces, cada función continua $X: E \rightarrow F$ es medible (O también llamada, \textit{función boreliana}).
\end{theorem}

Recuerde que, \textit{la función indicadora}, $f(x) = 1_A (x)$ se define como:

\[
	1_A (x) = \left\{  \begin{array}{lc}
		0 & x \in A \\
		1 & x \notin A
	\end{array} \right\}
\]

\begin{theorem}
	Sea $(F, \mathcal{F}) = (\mathbb{R}, \mathcal{B})$ y $(E, \mathcal{E})$ un espacio medible.

	\begin{itemize}
		\item Función indicadora $1_A$ en $E$ es medible si y sólo sí $A \in \mathcal{E}$
		\item Si $X_1, \cdots, X_n$ son funciones medibles de $(E, \mathcal{E})$ en $(\mathbb{R}, \mathcal{B})$, y si $f$ es borel en $\mathbb{R}^n$, luego $f(X_1, \cdots, X_n)$.
		\item Si $X, Y$ son medibles, luego $X + Y$, $XY$, $\max(X,Y)$, $\min{X,Y}$ y $X/Y$ con $Y \neq 0$ son medibles.
	\end{itemize}

\end{theorem}

Recordemos, para $X$ una variable aleatoria, será una función entre los espacios medibles $(\Omega, \mathcal{A})$ y $(E, \mathcal{E})$. Si dotamos al primer espacio de una probabilidad, $P$, de forma canónica podemos dotar al segundo espacio, de una medida de probabilidad, según $X$.

\begin{boxDef}
	Si $X$ es una variable aleatoria entre $(\Omega, \mathcal{A}, P)$, con valores en $(E, \mathcal{E})$, la \textbf{distribución} (O \textbf{medida de distribución}) de $X$, está definida por:

	\[
		P^{X} (B) = P(X^{-1} (B)) =  P(\{ \omega : X(\omega) \in B \}) = P(X \in B)
	\] 

	para todo $B \in \mathcal{E}$. 
\end{boxDef}

	Como la inversa se comporta bien bajo uniones e intersecciones, no es muy dificil probar que:

\begin{theorem}
	La distribución de $X$ es una medida de probabilidad en $(E, \mathcal{E})$
\end{theorem}

	Si $X$ es una variable aleatoria en $\mathbb{R}$, $P^{X}$ es una probabilidad en los reales, caracterizada por la función:

	\[
		F_X (x) = P^{X} ( (-\infty, x] ) = P(X \leq x)
	\]

	por el hecho, que los elementos en los borelianos, $\mathcal{B}$, pueden ser generador por elementos de la forma $(-\infty, x]$. $F_X (x)$ se conoce como \textbf{función de distribución cumulativa}.




















% ========================================
%================ SECCIÓN 1.3 Valor esperado. Integración bajo el signo de la integral.
% ========================================


\subsection{Integración respecto a medida de probabilidad. Valor esperado.}

Dada una variable aleatoria, en un espacio de probabilidad $(\Omega, \mathcal{A}, P)$, podríamos determinar un valor esperado, un promedio ponderado según la probabilidad, la imagen que se espera que tenga la variable aleatoria. \\

Para una variable aleatoria discreta, tenemos la definición:

% AGREGAR DEFINICIÓN PARA V.A DISCRETA

Ahora, queremos hallar el valor esperado para variables aleatorias en general. Consideramos algunos casos especiales inicialmente:

\begin{boxDef}
	Una variable aleatoria $X$ es \textbf{simple} si su imagen es un conjunto finito, por ende, para una familia de conjuntos disyuntos medibles, $ \left\{ A_i  \right\} \subset \mathcal{A}$, y constantes, $a_i \in \mathbb{R}$, para $1 \leq i \leq n$, veremos que la variable aleatoria tiene la forma:

	\[
		X = \sum_{i = 1}^n a_i 1_{A_i}
	\]

	Para $X$ variable aleatoria simple, podemos definir su \textbf{integral respecto a $P$} o \textbf{valor esperado} como:

	\[
		\mathbb{E}[X] = \sum_{i = 1}^n a_i P(A_i)
	\]
	o también denotado por $\int X dP$.

\end{boxDef}

Ahora, deseamos extender la definición para funciones más generales. Para esto, tendremos en cuenta los siguientes resultados:

\begin{theorem}
	Para cada variable aleatoria positiva $X$, existe una sucesión de variables aleatorias simples $\left\{ A_n \right\}_{n \geq 1}$ tal que $X_n$ tiende a $X$ de forma creciente, para $n \rightarrow \infty$ 
\end{theorem}

\textbf{Demostración:} Podemos tomar la sucesión:

\[
	X_n (\omega) = \left\{ \begin{matrix}
		k 2^{-n} & \text{si } k 2^{-n} \leq X(\omega) < (k+1) 2^{-n} \text{ y } 0 \leq k \leq n 2^n - 1 \\
		n & \text{si } X(\omega) \geq n
	\end{matrix}
	 \right.
\]

AÑADIR UNA GRAFICA

\begin{flushright}
	$\Box$
\end{flushright}


\begin{theorem}
	Sea $X$ una variable aleatoria positiva. Si $\left\{ X_n \right\}$ es sucesión de variables aleatorias simples que tienden de forma creciente a $X$, entonces $\mathbb{E}[X_n]$ tiende a $\mathbb{E}[X]$
\end{theorem}

Primero, podemos definir el valor esperado para variables aleatorias en positivas, esto es, que toma valores en $[0, \infty )$, como:

\[
	\int X dP = \mathbb{E}[X] = \sup \left\{ \mathbb{E}[Y] : Y \text{ es función simple con } 0 \leq Y \leq X \right\}
\]

De este modo, podemos definir:

\begin{boxDef}
	Sea $X^+ = \max (X, 0)$ y $X^- = -\min (X, 0)$. Una variable aleatoria $X$ es \textbf{integrable} si $\mathbb{E}[X^+] < \infty$ y $\mathbb{E}[X^-] < \infty$. En este caso, el \textbf{valor esperado} de $X$ se define como:

	\[
		\int X dP = \mathbb{E}[X] = \int X^+ dP + \int X^- dP = \mathbb{E}[X^+] + \mathbb{E}[X^-]
	\] 

	Tenemos que $\mathcal{L}^1$ o $\mathcal{L}^1 (\Omega, \mathcal{A}, P)$, es el conjunto de variables aleatorias que son integrables. \\ 

	% Admite valor esperado?

\end{boxDef}

Ya estamos listos para enunciar varias propiedades importantes de las variables aleatorias.

\begin{theorem}
	\begin{itemize}
		\item $\mathcal{L}^1$ es espacio vectorial, donde $\mathbb{E}$ es operador lineal, y para $X \in \mathcal{L}^1$ tal que $X \geq 0$, luego $\mathbb{E}[X] \geq 0$. Más aún, para $X \leq Y$, tenemos que $\mathbb{E}[X] \leq \mathbb{E}[Y]$.
		\item $X \in \mathcal{L}^1$ si y sólo si $| X | \in \mathcal{L}^1$.
		\item $\left\lvert \mathbb{E}[X] \right\rvert \leq \mathbb{E}[ \left\lvert X \right\rvert ]$. Mas aún, cualquier variable aleatoria acotada es integrable.
		\item Si $X = Y$ \textit{casi siempre} (Esto es, que $P(X = Y) = P(\left\{ \omega : X(\omega) = Y(\omega) \right\}) = 1$), entonces, $\mathbb{E}[X] = \mathbb{E}[Y]$. 
	\end{itemize}	

\end{theorem}

\begin{theorem}[Teorema de la convergencia monótona.]
	Si las variables aleatorias $X_n$ son positivas y tienden de forma creciente \textit{casi siempre} a X, luego $\lim_{n \rightarrow \infty} \mathbb{E}[X_n] = \mathbb{E}[X]$.
\end{theorem}

% ¿Esto está bien?
En este caso, $X_n$ tienden de forma creciente \textit{casi siempre} a X, si \\$P( \left\{ \omega : \lim_{n \rightarrow \infty } X_n (w) = X_n \right\} ) = 1$.

\begin{lema}[Lema de Fatou]
	Si las variables aleatorias $X_n$ satisfacen $X_n \geq Y$ \textit{casi siempre} ( $P( X_n \leq Y ) = P( \left\{ \omega : X_n(\omega) \leq Y(\omega) \right\}) = 1$ ) con $Y \in \mathcal{L}^1$, para todo $n$, entonces:

	\[
		\mathbb{E}\left[\liminf_{n \rightarrow \infty} X_n\right] \leq \liminf_{n \rightarrow \infty} \mathbb{E}[X_n]
 	\]

 	o se puede escribir como:

 	\[
 		\int_{\Omega} \liminf_{n \rightarrow \infty} X_n \leq \liminf_{n \rightarrow \infty} \int_{\Omega}  X_n
 	\]

 	En particular, si $X_n \leq 0$ \textit{casi siempre} para todo $n$, entonces se cumple la desigualdad.

\end{lema}

\begin{theorem}[Teorema de la convergencia dominada de Lebesgue]
	Si las variables aleatorias $X_n$ convergen \textit{casi siempre} a $X$ y si $\lvert X_n \rvert \leq Y$ \textit{casi siempre} para $Y \in \mathcal{L}^1$, para todo $n$, entonces, $X_n, X \in \mathcal{L}^1$, y:

	\[
		\lim_{n \rightarrow \infty } \mathbb{E}[X_n] = \mathbb{E}[X]
	\] 

	o

	\[
		\lim_{n \rightarrow \infty } \int_{\Omega} X_n = \int_{\Omega} X_n
	\]
\end{theorem}

Para consultar las pruebas, sugerimos consultar \cite{Probability_Essentials}. Ahora, estos teoremas poderosos, van a traer una serie de consecuencias, que serán útiles en la práctica. Enunciamos sin demostración.

\begin{theorem}
	Sea $X_n$ una sucesión de variables aleatorias.

	\begin{itemize}
		\item Si para todo $n$, $X_n$ es positiva, entonces:

		\[
			\mathbb{E} \left[ \sum_{n = 1}^{\infty} X_n  \right] =  \sum_{n = 1}^{\infty} \mathbb{E}[X_n]
		\]
		o

		\[
			\int_{\Omega} \sum_{n = 1}^{\infty} X_n  dP  =  \sum_{n = 1}^{\infty} \int_{\Omega} X_n dP
		\]

		\item Si $\sum_{n = 1}^{\infty} \mathbb{E}[ \lvert X_n \rvert ] < \infty$, luego $\sum_{n = 1}^{\infty} X_n$ converge \textit{casi siempre} y la suma de esta serie es integrable. 
	\end{itemize}
\end{theorem}

Antes de enunciar más propiedades, definimos los espacios $\mathcal{L}^p$.

\begin{boxDef}
	Para $1 < p < \infty$, definimos $\mathcal{L}^p$ el espacio de variables aleatorias tal que $\lvert X \rvert^p \in \mathcal{L}^1$.
\end{boxDef}


\begin{theorem}
	\begin{itemize}
		\item Si $X, Y \in \mathcal{L}^2$, entonces $XY \in \mathcal{L}^1$ y se cumple la desigualdad de \textit{Cauchy-Schwarz}:

		\[
			\lvert \mathbb{E}[XY] \rvert \leq \sqrt{ \mathbb{E}[X^2] \mathbb{E}[Y^2] }
		\] 
		\item $\mathcal{L}^2 \subset \mathcal{L}^1$. Si, $X \in \mathcal{L}^2$, luego $\left(\mathcal{E}[X] \right)^2 \leq \mathbb{E}[X^2]$.

		\item $\mathcal{L}^2$ es un espacio vectorial.
	\end{itemize}	
\end{theorem}

El siguiente resultado, permite calcular el valor esperado de cualquier función medible de una variable aleatoria.
	
\begin{theorem}[Regla del valor esperado.]
	Sea $X$ una variable aleatoria en $(\Omega, \mathcal{A}, P)$, con valores en $(E, \mathcal{E})$ y distribución $P^X$. Sea $h: (E, \mathcal{E}) \rightarrow (\mathbb{R}, \mathcal{B})$ una función medible.

	\begin{itemize}
		\item $h(X) \in \mathcal{L}^1 (\Omega, \mathcal{A}, P)$ si y sólo si $h \in \mathcal{L}^1 (E, \mathcal{E}, P^X )$.
		\item Si, $h$ es positiva, o se tienen las condiciones del inciso anterior, entonces:

		\[
			\mathbb{E}[h(X)] = \int_{\Omega} h(x) P^X(dx)
		\] 
	\end{itemize}

\end{theorem}

Finalmente, definimos varianza y mostramos una desigualdad conocida y bastante útil.

\begin{boxDef}
	Si $X \in \mathcal{L}^2$, la \textbf{varianza} de $X$, denotada por $\sigma_X^2$, está dada por:

	\[
		\sigma_X^2 = \mathbb{E}[ (X - \mathbb{E}[X])^2 ]
	\] 
	También llamado \textbf{segundo momento alrededor de la media} $\mu_2$.
\end{boxDef}


\begin{theorem}[Desigualdad de Chebyshev - Bienaymé]
	\[ P( \lvert X\rvert \geq a ) \leq \frac{ \mathbb{E}[X^2] }{ \sigma^2 } \]
\end{theorem}
















% ========================================
%================ SECCIÓN 1?? Probabilidad Condicional.
% ========================================


% \subsection{subsection name} 




















% ========================================
%================ SECCIÓN 1.4 Variables aleatorias independientes
% ========================================

\subsection{Variables aleatorias independientes.}	

Al tener dos variables aleatorias independientes, nos dará varias propiedades, por ejemplo, al tener la esperanza del producto de esas dos variables. De igual forma, vamos a definir $\sigma$-álgebras en $\mathbb{R}^n$.

\begin{boxDef}
	Dado $(\Omega, \mathcal{A}, P)$ un espacio de probabilidad. Dados eventos $A, B \in \mathcal{A}$, definimos la \textbf{probabilidad condicional} de $B$ dado $A$, como:

	\[
		P(B \vert A) = \frac{P(A \cap B)}{P(A)}
	\]

	siempre que $P(B) > 0$.

\end{boxDef}

De manera intuitiva, podemos ver que si $A$ y $B$ son dos eventos, tal que la ocurrencia de uno, no afecta a otro, o dicho de otra forma, son \textit{independientes}, entonces, sería razonable pensar que:

\[
	P(B \vert A) = P(B)
\]

porque el hecho que el evento $A$ ocurra, no afectará en nada a $B$. Formalizando, damos la siguiente definición:

\begin{boxDef}

	Dado $(\Omega, \mathcal{A}, P)$ y $\left\{ A_i \right\}_{i \in I}$ una colección (a lo más contable) de conjuntos medibles, que pertenecen a $\mathcal{A}$ (También llamados \textit{eventos}). Se dice que la colección es \textbf{colección independiente}, o \textbf{mutuamente independiente}, si dado $J \subset I$ conjunto finito de índices, se cumple que:

	\[
		P \left( \cap_{j \in J} A_j \right) = \prod_{j \in J} P(A_j)
	\].

	La colección es \textbf{independiente de a parejas}, si para todo $i, j \in I$, se tiene que $P(A_j \cap A_i) = P(A_j) P(A_i)$. 
	
\end{boxDef}

Tenga en cuenta, que si la colección $\left\{ A_i \right\}_{i \in I}$ es mutuamente independiente, entonces es independiente de a parejas. Sin embargo, la recíproca no se tiene.\\

Damos algunas propiedades y teoremas importantes acerca de eventos independientes.

\begin{theorem}
	Si $A, B$ son independientes, entonces:

	\begin{itemize}
		\item $A$, $B^c$
		\item $A^c$, $B$
		\item $A^c$, $B^c$	
	\end{itemize}

	son también independientes.

\end{theorem}


\begin{theorem}[Ley de la probabilidad total.]
	Dado $(\Omega, \mathcal{A}, P)$ un espacio de probabilidad. Sea $\left\{ E_n \right\}_{n \geq 1}$ una partición a lo más contable de $\Omega$. Luego, para un evento $A \in \mathcal{A}$, se cumple:

	\[
		P(A) = \sum_{n} P(A \vert E_n) P(E_n)
	\]

\end{theorem}

\begin{theorem}[Teorema de Bayes.]
	Dado $(\Omega, \mathcal{A}, P)$ un espacio de probabilidad. Sea $\left\{ E_n \right\}_{n \geq 1}$ una partición a lo más contable de $\Omega$, y sea $P(A) > 0$. Entonces:

	\[
		P(E_n \vert A) = \frac{ P(A \vert E_n) P(E_n) }{\sum_m P(A \vert E_m)P(E_m)}
	\]

\end{theorem}

Ahora, podemos generalizar el concepto de independencia a $\sigma$-álgebras, e inclusive, a variables aleatorias.

\begin{boxDef}
	Sea $(\Omega, \mathcal{A}, P)$ un espacio de probabilidad.
	\begin{itemize}
		\item Dadas sub-$\sigma$-álgebras $\left\{ A_i \right\}_{i \in I}$ de $\mathcal{A}$. Decimos que esta colección es \textbf{independiente} si para todo $J \subseteq I$ con $J$ finito, y todo $A_i \in \mathcal{A}_i$, se cumple que:

		\[
			P\left( \cap_{j \in J} A_j \right) = \prod_{j \in J} P(A_j)	
		\]
		En este caso, hablamos de \textbf{independencia de } $\sigma$ \textbf{-álgebras}. 

		\item Sea $\left\{ X_i \right\}_{i \in I}$ un conjunto de variables aleatorias en el espacio de probabilidad dado, tal que la imagen de $X_i$ es $(E_i, \mathcal{E_i})$. Decimos que las variables aleatorias son \textbf{independientes} si $\sigma (X_i) = X_i^{-1}(\mathcal{E_i})$ (Esto es, las $\sigma$-álgebras generadas por $X_i$) son independientes.
	\end{itemize}

\end{boxDef}

Enunciamos algunas propiedades para $X$ y $Y$ variables aleatorias independientes. De forma canónica, se puede extender el enunciado a un número a lo más contable de variables aleatorias independientes, $\left\{ X_i \right\}_{i \in I}$.

\begin{theorem}
	Sea $X, Y$ variables aleatorias cuya imagen son los espacios $(E, \mathcal{E})$ y $(F, \mathcal{F})$, respectivamente. $X$ y $Y$ son independientes si y sólo sí, se tiene algunas de las siguientes condiciones:

	\begin{itemize}
		\item $P(X \in A, Y \in B) = P(X \in A)P(Y \in B)$ para todo $A \in \mathcal{E}$ y $B \in \mathcal{F}$.
		\item $P(X \in A, Y \in B) = P(X \in A)P(Y \in B)$, para todo $A \in \mathcal{C}$, $B \in \mathcal{D}$ donde $\mathcal{C}, \mathcal{D}$ son clases de conjuntos cerrados bajo intersecciones finitas, tal que $\sigma(\mathcal{C}) = \mathcal{E}$ y $\sigma( \mathcal{D} ) = \mathcal{F}$
		\item Para $f, g$ funciones medibles, $f(X)$ y $g(X)$ son independientes.
		\item Para $f, g$ funciones medibles positivas, o medibles acotadas, $\mathbb{E}[ f(X)g(Y) ] = \mathbb{E}[f(X)] \mathbb{E}[g(Y)]$.
		\item Sean $E, F$ espacios métricos, y $\mathcal{E}, \mathcal{F}$ sus $\sigma$-álgebras de Borel. Entonces, $\mathbb{E}[ f(X)g(Y) ] = \mathbb{E}[f(X)] \mathbb{E}[g(Y)]$ para todas $f, g$ funciones acotadas y continuas.
	\end{itemize}

\end{theorem}

En este punto, vemos que estamos comenzando a tomar conjuntos de dos o más variables aleatorias. Sería deseable hablar de una noción de \textit{conjuntamente medible}. Sean $(E, \mathcal{E})$ y $(F, \mathcal{F})$ espacios medibles. En general, $\mathcal{E} \times \mathcal{F} = \left\{ A \subseteq E \times F | A = \Lambda \times \Gamma, \Lambda \in \mathcal{E}, \Gamma \in \mathcal{F} \right\}$ no será una $\sigma$-álgebra, por ejemplo, si tomamos el producto $\mathcal{B}(\mathbb{R}) \times \mathcal{B}(\mathbb{R})$ (Producto de los conjuntos de Borel en $\mathbb{R}$), es tentador pensar que tal producto es $\sigma$-álgebra de $\mathbb{R}^2$, sin embargo, note que el elemento $[0, 1] \times [0,1] \cup [-1, -1/2] \times [0, 1]$ debe estar en la $\sigma$-álgebra de $\mathbb{R}^2$, pero no está en $\mathcal{B}(\mathbb{R}) \times \mathcal{B}(\mathbb{R})$, falla la estabilidad bajo uniones. \\

Por tanto, denotaremos a:
\[
	\mathcal{E} \otimes \mathcal{F} = \sigma(\mathcal{E} \times \mathcal{F})
\]
como la menor $\sigma$-álgebra que contiene a $\mathcal{E} \times \mathcal{F}$. Tal cuál como las anteriores definiciones, enunciamos algunas propiedades y teoremas que serán de utilidad.

\begin{theorem}
	Sea $f: (E\times F, \mathcal{E} \otimes \mathcal{F}) \rightarrow (\mathbb{R}, \mathcal{R})$ función medible. Entonces, las secciones $y \rightarrow f(x, y)$ (Para todo $x \in E$) y $x \rightarrow f(x, y)$ (Para todo $y \in F$) son, respectivamente, $\mathcal{F}$-medible y $\mathcal{E}$-medible.
\end{theorem}

\begin{theorem}[Tonelli-Fubini]
	Sea $(E, \mathcal{E}, P)$ y $(F, \mathcal{F}), Q$ espacios de probabilidad. 

	\begin{itemize}
		\item Sea $R(A \times B) = P(A)Q(B)$, para $A \in \mathcal{E}$ y $B \in \mathcal{F}$. Entonces, $R$ se extiende de forma unívoca a una probabilidad en $(E \times F, \mathcal{E} \otimes \mathcal{F})$, denotada por $P \otimes Q$.

		\item Cada función $f$ que es $\mathcal{E} \otimes \mathcal{F}$-medible, positiva o integrable, respecto a $P \otimes Q$, tenemos que $x \rightarrow \int f(x,y) Q(dy)$ es $\mathcal{E}$-medible, $y \rightarrow \int f(x,y) P(dx)$ es $\mathcal{F}$-medible. Además:

		\[
			\int f dP\otimes Q = \int \left\{ \int f(x,y) Q(dy) \right\} P(dx) = \int \left\{ \int f(x,y) P(dx) \right\} Q(dy)
		\]

	\end{itemize}

\end{theorem}


Antes de acabar esta sección, vamos a ver dos teoremas importantes en probabilidad. Primero damos una definiciones:

\begin{boxDef}
	\begin{itemize}
		\item Sea $A_n$ una sucesión de eventos en $\mathcal{A}$. Definimos:

		\[
			\limsup_{n \rightarrow \infty } A_n = \cap_{n = 1}^{\infty} (\cup_{m \geq n}) A_m = \lim_{n \rightarrow \infty} (\cup_{m \geq n} A_m)
		\]
		De manera probabilística, podemos interpretar este evento como:
		\[
			\limsup_{n \rightarrow \infty} A_n = A_n \text{ ocurre \textbf{infinitamente seguido}}
		\]
		o del inglés, \textit{infinitely often (i.o)}. Esto es, que el evento $A_n$ ocurre para un número infinito de $n$. Podemos escribir:
		\[
			\limsup_{n \rightarrow \infty} A_n = \left\{ A_n \text{ i.o } \right\}
		\]

		\item Sean $X_n$ variables aleatorias definidas en $(\Omega, \mathcal{A}, P)$. Defina las $\sigma$-álgebras:

		\begin{align*}
			B_n &= \sigma(X_n)\\
			C_n &= \sigma(\cup_{p \geq n} B_n)\\
			C_{\infty} = \cap_{n=1}^{\infty} C_n
		\end{align*}

		$C_{\infty}$ es la $\sigma$-\textbf{álgebra cola}.

	\end{itemize}
\end{boxDef}


\begin{theorem}[Lema de Borel-Cantelli.]
	Sea $A_n$ una sucesión de eventos en $(\Omega, \mathcal{A}, P)$.

	\begin{itemize}
		\item Si $\sum_{n = 1}^{\infty} P(A_n) < \infty$, luego $P(A \text{i.o}) = 0$.
		\item Si $P(A_n \text{i.o}) = 0$ y si los eventos $A_n$ son mutuamente independientes, entonces $\sum_{n = 1}^{\infty} P(A_n) < \infty$. 
	\end{itemize}

\end{theorem}


\begin{theorem}[Ley cero-uno de Kolmogorov.]
	Sea $X_n$ una sucesión de variables aleatorias independientes, definidas en $(\Omega, \mathcal{A, P})$, y sea $C_{\infty}$ la $\sigma$-álgebra cola correspondiente. Si $C \in C_{\infty}$, entonces $P(C) = 0$ o $P(C) = 1$.
\end{theorem}






% ========================================
%================ SECCIÓN 1.5 Distribuciones en R, R^n. Variables multivariadas o Gaussianas.
% ========================================


\subsection{Distribuciones en $\mathbb{R}^n$ y variables aleatorias Gaussianas.}

% Colocar acerca de la función característica.














% ========================================
%================ SECCIÓN 1.6 Convergencia de variables aleatorias.
% ========================================


\subsection{Convergencia de variables aleatorias.}





% ========================================
%================ SECCIÓN 1.7 Esperanza Condicional
% ========================================

\subsection{Esperanza Condicional.}

Para $X, Y$ variables aleatorias (Con $Y$ tomando valores de $\mathbb{R}$ y $X$ toma valores a lo sumo contables), ya sabemos calcular el valor de $P(Y \vert X = i)$, esto es, la probabilidad condicional de $Y$ dado $X = i$. Deseamos extender este concepto, para poder calcular el valor esperado de la variable aleatoria $Y$, dado que $X = i$, esto es, una \textit{esperanza condicional.}

\begin{boxDef}
 	Dado $X$ que toma valores en $\left\{ x_1, \cdots, x_n, \cdots \right\}$ (Conjunto a lo sumo contable), y $Y$ una variable aleatoria. Si $P(X = x_j) > 0$, entonces la \textbf{esperanza condicional de $Y$ dado $\left\{ X = x_j \right\}$} está definida por:

 	\[
 		\mathbb{E} [Y \vert X = x_j] = \mathbb{E}_Q [Y] = \int Y dQ
 	\]

 	tal que $Q(\Lambda) = P(\Lambda \vert X = x_j)$, y dado que $\mathbb{E}_Q [ \lvert Y \rvert] < \infty$.
\end{boxDef} 

Una forma clásica de calcular esta esperanza condicional, con $Y$ tomando valores de un conjunto a lo más contable, está enunciada en este teorema, que es consecuencia de la definición:

\begin{theorem}
	Asuma las condiciones de la definición anterior. Además, si $Y$ tiene valores contables $\left\{ y_1, \cdots, y_n, \cdots \right\}$ y si $P(X = x_j) > 0$, entonces:

	\[
		\mathbb{E}[Y \vert X = x_j] = \sum_{k = 1}^{\infty} y_k P(Y = y_k \vert X = x_j)
	\]
	dado que la serie converge absolutamente.
\end{theorem}

Sin embargo, no todas las variables aleatorias tomarán valores de un conjunto a lo más contable, deseamos extender la definición a variables aleatorias más generales. Primero, podemos definir la esperanza condicional, entre dos variables aleatorias. 

\begin{boxDef}
	Sea:

	\[
		f(x) = \left\{  
		\begin{matrix}
			\mathbb{E}[Y \vert X = x] & \text{ si } P(X = x) > 0 \\
			\text{Otro valor} & \text{ si } P(X = x) = 0
		\end{matrix} \right.
	\]

	Dado $X$ con valores contables, y $Y$ una variable aleatoria con valores en $\mathbb{R}$. La \textbf{esperanza condicional de $Y$ dado $X$} está definida por:

	\[
		\mathbb{E}[Y \vert X] = f(Y)
	\]
\end{boxDef}

Note que la definición está dada por eventos que ocurren \textit{casi siempre (a.s)}, es decir, salvo en elementos, donde la probabilidad sea $0$. Ahora, si $X$ toma valores reales, en general los eventos $\{ X = x_j\}$ tendrán probabilidad $0$ y el enfoque dado no funciona. \\

Sin embargo, lo que se realizó fue hallar una función $f$ auxiliar, para hallar la esperanza condicional, y este será el enfoque que se tomará para el caso en general. Para cumplir el objetivo, se usará el siguiente teorema.

\begin{theorem}[Lema de Doob-Dynkin.]
	Sea $X$ una variable aleatoria con valores en $\mathbb{R}^n$, y $Y$ una variable aleatoria con valores en $\mathbb{R}$. $Y$ es medible con respecto a $\sigma (X)$ (La $\sigma$-álgebra generada por $X$) si y sólo si existe una función $f: \mathbb{R}^n \rightarrow \mathbb{R}$ que sea Borel-medible tal que $Y = f(X)$.
\end{theorem}

% ¿Colocar ejemplos?


Sea $(\Omega, \mathcal{A}, P)$ un espacio de probabilidad, y $X: \Omega \rightarrow \mathbb{R}^n$ una variable aleatoria. Recuerde que, $\mathcal{L}^2$ es el espacio de los \textit{cuadrado-integrables}, esto es, que para $Y \in \mathcal{L}^2$, $\mathbb{E}[Y^2] < \infty$ (O $\int_{\Omega} Y^2 dP < \infty $ ). Como $\mathcal{L}^2 (\Omega, \mathcal{A}, P)$ es un \textit{espacio de Hilbert}, entonces se puede definir un producto interno en este espacio:

\[
	\langle Y, Z \rangle = \int_{\Omega} Y Z dP = \mathbb{E}[YZ]
\]
Como $\sigma(X) \subset \mathcal{A}$, entonces $(\Omega, \sigma(X), P)$ es también un subespacio de Hilbert. Dado estos conceptos, se procede a generalizar la esperanza condicional.

\begin{boxDef}
	Sea $Y \in \mathcal{L}^2 (\Omega, \mathcal{A}, P)$. La \textbf{esperanza condicional de $Y$ dado $X$} es el único $\hat{Y} \in \mathcal{L}^2 (\Omega, \sigma(X), P)$ tal que:
	\[
		\mathbb{E}[\hat{Y}X] = \mathbb{E}[YZ]
	\]
	para todo $Z \in \mathcal{L}^2 (\Omega, \sigma(X), P)$, se denota como $\mathbb{E}[Y \vert X] = \hat{Y}$.
\end{boxDef}

Note que la esperanza condicional de $Y$ dado $X$, será la proyección de $Y$ en el subespacio de Hilbert $\mathcal{L}^2 (\Omega, \sigma(X), P)$. Para más detalles de análisis funcional, consulte el apéndice.

Como $\hat{Y}$ es $\sigma (X)$-medible, por el lema de Doob-Dynkin, existe una función $f$ Borel medible tal que:

\[
	\mathbb{E}[Y \vert X] = f(X)
\]

Entonces, se tiene una expresión alternativa para el teorema de Doob-Dynkin; para toda función $g$ Borel-medible tal que $g(X) \in \mathcal{L}^2$:

\[
	\mathbb{E}[f(X) g(X)] = \mathbb{E}[Y g(X)]
\]

Ahora, se puede definir la esperanza condicional respecto a una $\sigma$-álgebra.

\begin{boxDef}
	Sea $Y \in \mathcal{L}^2 (\Omega, \mathcal{A}, P)$ y $\mathcal{G}$ una sub-$\sigma$-álgebra de $\mathcal{A}$. Definimos la \textbf{esperanza condicional de $Y$ respecto a $\mathcal{G}$} como el único elemento $\mathbb{E}[Y \vert \mathcal{G}] \in \mathcal{L}^2 (\Omega, \mathcal{G}, P)$ tal que:

	\[
		\mathbb{E}[Y Z] = \mathbb{E}[ \mathbb{E}[Y \vert \mathcal{G}] Z ]
	\] 
	para todo $Z \in \mathcal{L}^2 (\Omega, \mathcal{G}, P)$. También podemos escribir como:

	\[
		\mathbb{E}[Y \vert \mathcal{G}] = \int_{\Lambda} Y dP
	\]
	para todo $\Lambda in \mathcal{G}$.
\end{boxDef}

Note que, $\mathbb{E}[Y \vert \mathcal{G}]$ se puede ver como la proyección de $Y$ sobre el subespacio de Hilbert $(\Omega, \mathcal{G}, P)$. \\

Como dato adicional, es importante recalcar que la esperanza condicional es un elemento de $\mathcal{L}^2$, y es una \textit{clase de equivalencia} de alguna variable aleatoria. Por ende, relaciones del tipo $\mathbb{E}[Y \vert \mathcal{G}] \geq 0$ o $\mathbb{E}[Y \vert \mathcal{G}] = Z$ se sobreentienden como relaciones que se cumplen en \textit{casi siempre} o en \textit{casi todo sitio} (Esto es, se preserva la igualdad salvo en conjuntos nulos o de medida cero).\\

Al igual que el operador $\mathbb{E}$ cumple varias propiedades, también $\mathbb{E}[\cdot \vert  \cdot]$ cumple propiedades similares.

\begin{theorem}[Propiedades de la esperanza condicional.]
	Sea $Y \in \mathcal{L}^2 (\Omega, \mathcal{A}, P)$ y $\mathcal{G}$ una sub-$\sigma$-álgebra de $\mathcal{A}$. Entonces, 

	\begin{itemize}
		\item Si $Y \geq 0$, luego $\mathbb{E}[Y \vert \mathcal{G}] \geq 0$.
		\item Si $\mathcal{G} = \sigma (X)$ para cierta variable aleatoria $X$, entonces existe una función Borel medible $f$ tal que $\mathbb{E}[Y \vert \mathcal{G}] = f(X)$.
		\item $\mathbb{E}[\mathbb{E}[Y \vert \mathcal{G}]] = \mathbb{E}[Y]$.
		\item La función $Y \rightarrow \mathbb{E}[Y \vert \mathcal{G}]$ es lineal.
	\end{itemize}
\end{theorem}


\begin{theorem}
	Sea $Y \in \mathcal{L}^{+}(\Omega, \mathcal{A}, P)$ (El espacio de variables aleatorias no negativas), y sea $\mathcal{G}$ una sub-$\sigma$-álgebra de $\mathcal{A}$. Entonces existe un único elemento $\mathbb{E}[Y \vert \mathcal{G}]$ de $\mathcal{L}^{+}(\Omega, \mathcal{G}, P)$ tal que:

	\[
		\mathbb{E}[Y X] = \mathbb{E}[ \mathbb{E}[Y \vert \mathcal{G}] X ]
	\]
 	
 	para todo $X \in \mathcal{L}^{+}(\Omega, \mathcal{G}, P)$. Más aún, si $0 \leq Y \leq Y'$, luego:

 	\[
 		\mathbb{E}[Y \vert \mathcal{G}] \leq \mathbb{E}[Y' \vert \mathcal{G}],
 	\]
 	es decir, la esperanza condicional es monótona creciente.
\end{theorem}

\begin{theorem}
	Sea $Y \in \mathcal{L}^{+}(\Omega, \mathcal{A}, P)$ y $\mathcal{G}$ una sub-$\sigma$-álgebra de $\mathcal{A}$. Entonces, existe un único elemento $\mathbb{E}[Y \vert \mathcal{G}] \in \mathcal{L}^1 (\Omega, \mathcal{G}, P)$ tal que:

	\[
		\mathbb{E}[Y X] = \mathbb{E}[ \mathbb{E}[Y \in \mathcal{G}] X ]
	\]
	para toda $X$ que es acotada y $\mathcal{G}$-medible. Además, se cumple:

	\begin{itemize}
		\item Si $Y \geq 0$, luego $\mathbb{E}[Y \vert \mathcal{G}] \geq 0$.
		\item $Y \rightarrow \mathbb{E}[Y \vert \mathcal{G}]$ es un mapa lineal. 
	\end{itemize}

\end{theorem}

Note que, se han visto algunas definiciones equivalentes a la esperanza condicional. \\

Ahora, se puede caracterizar la esperanza condicional para diversos casos, como cuando una variable aleatoria es medible respecto a una sub-$\sigma$-álgebra.

\begin{theorem}
	Sea $Y$ una variable aleatoria positiva o integrable en $(\Omega, \mathcal{A},P)$, y sea $\mathcal{G}$ una sub-$\sigma$-álgebra. Entonces, $\mathbb{E}[Y \vert \mathcal{G}] = Y$ si y sólo si $Y$ es $\mathcal{G}$-medible.
\end{theorem}

Al tomar dos variables aleatorias, y colocar condiciones, se pueden obtener resultados interesantes.

\begin{theorem}
	Sea $Y \in \mathcal{L}^1 (\Omega, \mathcal{A}, P)$, y sea $X, Y$ independientes, luego:

	\[
		\mathbb{E}[Y \vert X] = \mathbb{E}[Y]
	\]
\end{theorem}


\begin{theorem}
	Sea $X, Y$ variables aleatorias en $(\Omega, \mathcal{A}, P)$, sea $\mathcal{G}$ una sub-$\sigma$-álgebra de $\mathcal{A}$, y suponga que $X$ es $\mathcal{G}$-medible. Si $X, Y$ y $XY$ son integrables, o si $X,Y$ son positivos, tendremos que:
	$\mathbb{E}[XY \vert \mathcal{G}] = X \mathbb{E}[Y \vert \mathcal{G}]$
\end{theorem}

En la esperanza condicional, también se tendrán los teoremas importantes de convergencia, que se tenían para la esperanza usual.

\begin{theorem}[Teoremas de convergencia para la esperanza condicional.]
	Sea $\left\{ Y_n \right\}_{n \geq 1}$ una sucesión de variables aleatorias en $(\Omega, \mathcal{A}, P)$, y sea $\mathcal{G}$ una sub-$\sigma$-álgebra de $\mathcal{A}$.

	\begin{itemize}
		\item \textbf{(Convergencia monótona).} Si $Y_n \geq 0$, $n \geq 1$ y $Y_n \rightarrow Y$ de forma creciente, luego, \textit{casi siempre} se tiene:

		\[
			\lim_{n \rightarrow \infty} \mathbb{E}[Y_n \vert \mathcal{G}] = \mathbb{E}[Y \vert \mathcal{G}]
		\]

		\item \textbf{(Lema de Fatou).} Si $Y_n \geq 0$, $n \geq 1$, entonces:

		\[
			\mathbb{E}[ \liminf_{n \rightarrow \infty} Y_n \vert \mathcal{G} ] \leq \liminf_{n \rightarrow \infty} \mathbb{E}[Y_n \vert \mathcal{G}]
		\]

		\item \textbf{(Teorema de la convergencia dominada de Lebesgue.)} Si $\lim_{n \rightarrow \infty} Y_n = Y$ \textit{casi siempre}, y $\lvert Y_n \rvert \geq Z$, con $n \geq 1$ para algún $Z \in \mathcal{L}^1 (\Omega, \mathcal{A}, P)$, entonces, \textit{casi siempre}:

		\[
			\lim_{n \rightarrow \infty} \mathbb{E}[Y_n \vert \mathcal{G}] = \mathbb{E}[Y \vert \mathcal{G}]
		\]


	\end{itemize}

\end{theorem}

Se finaliza la sección, con algunas desigualdades importantes que involucran a la esperanza condicional.

\begin{theorem}[Desigualdad de Jensen.]
	Dada $\phi: \mathbb{R} \rightarrow \mathbb{R}$ una función convexa, y sea $X$, $\phi(X)$ variables aleatorias. Entonces, para toda sub-$\sigma$-álgebra, se tiene que:

	\[
		\phi \left( \mathbb{E}[X \vert \mathcal{G}] \right) \leq \mathbb{E}[\phi(X) \vert \mathcal{G} ]
	\]
\end{theorem}

Como consecuencia de la desigualdad de Jensen, se tiene:

\begin{theorem}[Desigualdad de Hölder.]
	Dados $X, Y$ variables aleatorias, tal que $\mathbb{E}[ \lvert X \rvert^p ] \leq \infty$, $\mathbb{E}[ \lvert Y \rvert^q ] \leq \infty$ con $p > 1$, y $\frac{1}{p} + \frac{1}{q} = 1$. Luego:

	\[
		\mathbb{E}[ \lvert XY \rvert ] \leq \mathbb{E}[ \lvert X \rvert^p ]^{\frac{1}{p}} \mathbb{E}[ \lvert Y \rvert^q ]^{\frac{1}{q}}
	\]
\end{theorem}

Y de igual forma, se tiene una consecuencia de la desigualdad de Hölder:

\begin{theorem}[Desigualdad de Minkowski.]
	Dada $X, Y$ variables aleatorias, $1 \leq p < \infty$ con $\mathbb{E}[ \lvert X \rvert^p ] < \infty$ y $\mathbb{E}[ \lvert Y \rvert^p ] < \infty$. Luego:

	\[
		\mathbb{E}[ \lvert X + Y \rvert^p ]^{ \frac{1}{p} } \leq \mathbb{E}[X^p]^{\frac{1}{p}} + \mathbb{E}[Y^p]^{\frac{1}{p}}
	\]
\end{theorem}


% Variables aleatorias. OK

% Medida de probabilidad. OK

% Probabilidad Condicional. ¿?

% Independencia de variables aleatorias. OK

% Integración respecto a medida de probabilidad. OK

% Distribuciones en R^n. Variables aleatorias Gaussianas.

% Convergencia de VARIABLES ALEATORIAS, Ley de los grandes números.

% Esperanza Condicional, OK.

% -> Apéndice L2 y Espacios de Hilbert.

% Sí, Función característica.


























% PROCESOS ESTOCÁSTICOS



% ========================================
%================ SECCIÓN ?. PROCESOS ESTOCÁSTICOS. (CAPÍTULO MOVIMIENTO BROWNIANO)
% ========================================

%\section{Procesos Estocásticos.}















% ========================================
%================ SECCIÓN 2. PRELIMINARES DE INTEGRACIÓN Y ECUACIONES DIFERENCIALES.
% ========================================

\section{Preliminares de Integración y Ecuaciones Diferenciales.}

En esta sección, se hablará un poco acerca de temas de Integración, como la integral de Riemann-Stieltjes, la integración de Young y algunos teoremas importantes para poder estudiar caminos rugosos.

De igual forma, se verá una breve introducción a las ecuaciones diferenciales ordinarias, enunciando algunos teoremas de existencia y unicidad. Este será útil, al demostrar el teorema de existencia y unicidad en ecuaciones diferenciales estocásticas.





% ========================================
%================ SECCIÓN 2.1 Ecuaciones Diferenciales Ordinarias e Integración.
% ========================================


\subsection{Ecuaciones Diferenciales Ordinarias Controladas e Integración..}


En esta sección, se hablarán algunos aspectos breves acerca de las ecuaciones diferenciales controladas, y ciertos problemas que estas pueden poseer. También se hablará brevemente \textit{integral de Riemann-Stieltjes} (Para un tratamiento más extenso, consulte \cite{Mathematical_Analysis_Apostol}) y también sobre la \textit{integral de Young}, y finalmente, se observará que estas integrales en ciertas ocasiones no son suficientes al tener caminos poco regulares.


Sea $\Omega \subset \mathbb{R} \times \mathbb{R}^n$. Definimos una \textit{norma} en $\mathbb{R} \times \mathbb{R}^n$ como:

\[
	\lvert (t,x) \rvert = \max\left\{ \lvert t \rvert, \lVert x \rVert \right\}.
\] \\

\begin{boxDef}
	Sea $f: \Omega \rightarrow \mathbb{R}^n$ una función continua, e $I$ un intervalo conexo de $\mathbb{R}$ no reducido a un punto. Entonces, se dice que una función diferenciale $\phi: I \rightarrow \mathbb{R}^n$ es una \textbf{solución de la ecuación diferencial}

	\[
		\frac{dx}{dt} = f(t, x)
	\]

	en el intervalo $I$ si se cumplen las condiciones:

	\begin{itemize}
		\item $\left\{ (t, \phi(t) ) \vert t \in I  \right\} \subset \Omega$.
		\item $\frac{d\phi}{dt} (t) = f(t, \phi(t))$ para todo $t \in T$. 
	\end{itemize}

	La ecuación diferencial mostrada, es una \textbf{ecuación diferencial ordinaria de primer orden.}

\end{boxDef}

En general, se observa que las ecuaciones diferenciales ordinarias, son un tipo de \textbf{sistema controlado de ecuaciones diferenciales}:

\[
	dY_t = f(Y_t) dX_t
\]

donde $f$ se puede pensar como un campo vectorial, $Y: [0, T] \rightarrow \mathbb{R}^n$ es la solución y $X: [0, T] \rightarrow \mathbb{R}^d$ es una \textit{señal de entrada}. Si tenemos que $X_t$ es absolutamente continua, se tendrá una EDO. Pero, ¿Qué pasa si $X_t$ toma otra forma? De forma integral, la expresión de arriba se puede reescribir como:

\[
	Y_t = Y_0 + \int_0^t f(Y_s) dX_s
\]

y el problema es sobre cómo definir la integral $\int f dX_s$, por ejemplo, si $X_t$ es una función con baja regularidad, como un movimiento de ruido blanco, u otro proceso estocástico. Una solución a medias, bajo una topología sutil se podría aproximar por caminos suaves $X_n \rightarrow X$ y $Y_n \rightarrow Y$, como:

\[
	\int_0^t f(Y_s) dX_s = \lim_{n \rightarrow \infty} f(Y^n_s) dX^n_s
\]

Por ejemplo, al tener funciones continuas, se podría tomar la norma del supremo, que es la topología de la convergencia uniforme. Comenzando por el caso más simple, se puede definir la integral de Riemann-Stieljes:

\begin{boxDef}
	Sea $\pi = \left\{ 0 = t_0, t_1, \cdots, t_N  = T\right\}$ una partición de $[0,T]$. Sea $\pi_n  = \left\{ 0 = t_0^n, t_1^n, \cdots, t_N^n  = T\right\} $ una sucesión de particiones tal que $\lvert \pi_n \rvert \rightarrow 0$ para $n \rightarrow \infty$, con $u_i^n \in [t_i^n, t_{i+1}^n]$. Para $Y$ camino continuo, y $X$ camino de variación acotada, definimos la \textbf{integral de Riemann-Stieljes} como:

	\[
		\int_0^T Y_s dX_s = \lim_{n \rightarrow \infty} \sum_{i = 0}^{N_{n-1} } Y_{u_i^n} (X_{t_{i+1}^n} -  X_{t_i^n})
	\]

\end{boxDef}

Gracias a las condiciones de los caminos $Y$ y $X$, la integral no dependerá del punto $u_i^n$ seleccionado en el intervalo de la partición, lo que es una gran ventaja. Sin embargo, este lujo se pierde al hacer los caminos menos regulares.

Se puede debilitar la condición de continuidad de los caminos, por un concepto más débil.

\begin{boxDef}
	Para $\alpha \in (0, 1]$, un camino $X: [0, T] \rightarrow \mathbb{R}^d$ es $\alpha$\textbf{-Hölder continuo} si existe $C$ constante tal que:

	\[
		\lvert X_t - X_s \rvert \leq C \lvert t - s \rvert^{\alpha}
	\]

	para todo $t, s \in [0, T]$ con $s < t$.
\end{boxDef}

De esta forma, definimos la \textbf{integración de Young}.

\begin{theorem}[Integración de Young.]
\label{thm:Young}
	Sea $\alpha, \beta \in (0, 1]$ tal que:

	\[
		\alpha + \beta > 1
	\]

	Sea $X$ una función $\alpha$-Hölder continua, y $Y$ $\beta$-Hölder continua. Sea $\pi_n = \{ t_0^n, \cdots, t_N^n  \}$ sucesión de particiones con $\lvert \pi_n \rvert \rightarrow 0$ para $n \rightarrow 0$. Para todo $n \geq 1$, e $i = 0, 1, \cdots, N - 1$, tomando $u_i^n \in [t_i^n, t_{i+1}^n]$. Luego el límite

	\[
		\int_0^T Y_s dX_s = \lim_{n \rightarrow \infty} \sum_{i = 0}^{N_n - 1} Y_{u_n^i} (X_{t_{i+i}^n} - X_{t_i^n} )
	\] 
	llamada \textbf{integral de Young}, existe, y no depende de la sucesión $\{ \pi_n \}$, ni de la elección del punto $u_i^n$.

\end{theorem}

Al trabajar en ecuaciones diferenciales estocásticas, usualmente el integrador es $X_s = B_s$, un movimiento Browniano, que tiene muy baja regularidad. Por el teorema de continuidad de Kolmogorov (Capítulo 2), las trayectorias del Browniano son \textit{casi siempre} $\alpha$-Hölder continuas para $\alpha < \frac{1}{2}$. En este caso, no se pueden cumplir siempre las condiciones de la integral de Young, por ende, es mejor cambiar el enfoque.

Más adelante, en el presente trabajo, se hablará acerca del movimiento Browniano, y la construcción de la integral de Itô, como una solución para atacar la baja regularidad.




% ========================================
%================ SECCIÓN 2.2 Teoremas de Existencia y Unicidad
% ========================================


\subsection{Teoremas de Existencia y Unicidad.}

De forma preliminar, las ecuaciones diferenciales se han usado a lo largo de los años para modelar distintos fenómenos naturales, económicos, etc... y es natural preguntarse si es posible solucionar cierta ecuación diferencial, obtener una solución y determinar un modelo matemático a cierto fenómeno. En este apartado, se formalizará estos conceptos, y se mostrarán los teoremas de existencia y unicidad, con su demostración. \\


Ahora, consideramos el \textit{problema de Cauchy}, o específicamente, \textit{problema de valor inicial}:

\[
	\frac{dx}{dt} = f(t, x) \text{, sujeto a } x(t_0) = x_0
\]

Bajo algunas condiciones sutiles, esta ecuación diferencial tiene solución y es única. Primero, se muestran algunas definiciones y un lema importante, antes de pasar a trabajar la existencia y unicidad de la solución.

\begin{boxDef}
	Una función $f: \Omega \subset \mathbb{R} \times \mathbb{R}^n \rightarrow \mathbb{R}^n$ es una función \textbf{Lipschitz-continua} en $\Omega$ (En este caso, respecto a la segunda variable), si existe $K \in \mathbb{R}$ constante tal que:

	\[
		\lvert f(t,x) - f(t,y) \rvert \leq K \lvert x - y \rvert
	\]
	para toda $(t,x), (t,y) \in \Omega$.

	Si para una vecindad de $(t_0, x_0) \in \Omega$, $V_{\mathbb{R}}(t_0, x_0; \epsilon)$, la función es Lipschitz-continua, entonces se dice \textbf{localmente Lipschitz-continua.}

\end{boxDef}

Note que, si $f$ tiene derivada parcial respecto a la segunda variable, $D_2 f$, que está acotada, $\lVert D_2 f \rVert \leq K$ y $\Omega$ es un conjunto convexo, entonces, por el teorema del valor medio, tendremos:

\[
	\lvert f(t,x) - f(t, y) \rvert \leq \sup_{0 \leq \theta \leq 1} \lVert D_2 f(t, \theta x + (1 - \theta)y) \rVert \lvert x - y \rvert \leq K \lvert x - y \rvert
\] 

\begin{lema}[Lema de la contracción (Punto fijo de Banach).]
	Dado $(X, d)$ un espacio métrico completo, $F: X \rightarrow X$ una contracción, esto es, $d(F(x), F(y)) \leq K d(x, y)$ para $0 <  K < 1$. Entonces, $F$ tiene un único punto fijo $p$. Más aún, $F^n (x) = F(F^{n-1}(x)) \rightarrow p$ cuando $n \rightarrow \infty$ para todo $x \in X$. En este caso, $p$ se conoce como \textbf{atractor} de F.
\end{lema}

\begin{coro}
	Dado $(X, d)$ un espacio métrico completo. Si $F: X \rightarrow X$ es continua, y para algún $m$, $F^m$ es contracción, luego existe un único punto fijo para $F$. Más aún, ese punto fijo $p$ es atractor de $F$.
\end{coro}

Ya con estos resultados, comenzamos a trabajar los teoremas de existencia y unicidad de soluciones en ecuaciones diferenciales ordinarias.

\begin{theorem}[Teorema de Picard.]
	Sea $f$ una función continua, y de Lipschitz en $\Omega = I_a \times B_b$, donde $I_a = \left\{ t \vert \lvert t - t_0 \rvert \leq a \right\}$ y $B_b = \left\{ x \vert \lVert x - x_0 \rVert \leq b \right\}$. Sea $\lvert f \rvert \leq M$, esto es, la función está acotada. Entonces, el problema:

	\[
		\frac{dx}{dt} = f(t,x),\ x(t_0) = x_0
	\]
	tiene solución única en $I_{\alpha}$ con $\alpha = \min \left\{ a, b/M \right\}$
\end{theorem}

\textbf{Demostración.} Sea $X = \mathcal{C}(I_a, B_b)$ el espacio métrico completo de funciones $\phi: I_a \rightarrow B_b$ continuas, equipado de la métrica uniforme;

\[
	d(\phi_1, \phi_2) = \sup_{t \in I_{\alpha}} \lvert \phi_1 (t) - \phi_2 (t) \rvert
\]

Para $\phi \in X$, sea $F(\phi): I_{\alpha} \rightarrow \mathbb{R}^n$ definida como:

\[
	F(\phi) (t) = x_0 + \int_{t_0}^{t} f(s, \phi(s)) ds
\]

con $t \in I_{\alpha}$. Podemos verificar lo siguiente:

\begin{itemize}
	\item $F(X) \subseteq X$.

	Tomando $t \in I_{\alpha}$, tenemos:

	\begin{align*}
		\lvert F(\phi)(t) - x_0 \rvert &= \left\lvert \int_{t_0}^t f(s, \phi(s)) ds \right\rvert \quad  \text{, definición de } F \\
		&\leq M \alpha \quad  \text{, } f \text{ está acotado y } \lvert t - t_0 \rvert\leq \alpha \\
		&\leq b \quad \text{ porque } M\alpha = \min \left\{ M a, b \right\}
	\end{align*}

	y así, $F(\phi)(t) \in B_b$, y como $F(\phi)$ es continua, tenemos que $F(X) \subset X.$

	\item Para $n$ suficientemente grande, $F^n (X)$ es contracción.

	Tomando $\phi_1, \phi_2 \in X$, y $n \geq 0$. La idea es probar que:

	\[
		\left\lvert F^{(n)} (\phi_1)(t) - F^{(n)} (\phi_2)(t) \right\rvert \leq \frac{K^n (t-t_0)^n}{n!} d(\phi_1, \phi_2)
	\]

	con $t \in I_{\alpha}$. La prueba es por inducción sobre $n$. El caso $n = 0$ es trivial. Suponer que se tiene lo deseado para $n = k$, entonces, se prueba para $k + 1$;

	\begin{align*}
		\lvert F^{(k+1)} (\phi_1)(t) - F^{(k+1)}(\phi_2)(t) \rvert &= \lvert F( F^{(k)}(\phi_1) )(t) - F( F^{(k)}(\phi_2) )(t) \rvert \\
		&\leq \left\lvert \int_{t_0}^t \lvert f(s, F^{(k)} (\phi_1)(s) ) - f(s, F^{(k)} (\phi_2)(s) )  \rvert \right\rvert \\
		&\leq \left\lvert \int_{t_0}^t K \lvert F^{(k)} (\phi_1)(s) - F^{(k)} (\phi_2)(s) \rvert \right\rvert \\
		&\leq K \left\lvert \int_{t_0}^t \frac{K^k (t_0 - s)^k}{k!} d(\phi_1, \phi_2) ds \right\rvert\\
		&= \frac{K^{k+1} \lvert t_ - t_0 \rvert^{k+1} }{(k+1)!} d(\phi_1, \phi_2)
	\end{align*}

	donde este último paso se obtiene al realizar la integral. Entonces, ya queda probado que:

	\[
		d( F^{(n)} (\phi_1), F^{(n)} (\phi_2) ) \leq \frac{K^n \alpha^n}{n!} d(\phi_1, \phi_2)
	\]

	para $n$ suficientemente grande. Además, también para un $n$ grande, se tendrá que $\frac{K^n \alpha^n}{n!} \leq 1$, porque el término de este serie debe converger a $e^{k\alpha}$, si fuera mayor a $1$, la serie no converge.

	Así, queda probado que $F^{n}$ es contracción de $X$.

\end{itemize}

Entonces, por el corolario consecuencia del lema de contracción, existe una función $\phi \in X$ tal que $F(\phi) = \phi$, y de esta forma, queda demostrado lo deseado.

% colocar dibujo!!!!


\begin{flushright}
	$\Box$
\end{flushright}

En el teorema de Picard, se puede relajar las hipótesis, y se puede retirar la condición de Lipschitz, para obtener otra versión del teorema más general. Para ello, se presentan primero dos teoremas necesarios (Sin demostración) usados en la prueba del teorema general.

\begin{theorem}[Teorema de Ascoli-Arzelá.]
	Sea $(X, d)$ un espacio métrico compacto. Sea $F$ una familia equicontinua de funciones $\phi: X \rightarrow \mathbb{R}$ (Esto es, para todo $\epsilon > 0$, existe un $\delta > 0$ tal que si $d(x, y) < \delta$, luego $\lvert \phi(x) - \phi(y) \rvert < \epsilon$, para toda $\phi \in F$). Sea $F$ uniformemente acotada (Existe $M > 0$ tal que para todo $\phi \in F$, $\lvert \phi \rvert < M$), entonces, toda sucesión $\left\{ \phi_n \right\}$ en $F$, tiene subsucesión uniformemente convergente en $X$.
\end{theorem}

\begin{theorem}[Teorema de la aproximación de Weierstrass.]
	Para cualquier $\epsilon > 0$ y para cualquier función $f$ continua en un intervalo $[a,b] \subset \mathbb{R}$, existe un polinomio de coeficientes reales $p$ tal que

	\[
		\sup_{x \in [a,b]} \lvert f(x) - p(x) \rvert < \epsilon	
	\]
\end{theorem}

Esto es, se puede aproximar una función por una sucesión de polinomios con coeficientes reales, tal que converjan uniformemente.

\begin{theorem}[Teorema de Peano.]
	Sea $F$ continua en $\Omega = I_a \times B_b$, definidos como en el teorema de Picard. Si $\lvert f \rvert < M$ en $\Omega$, luego la ecuación diferencial:

	\[
		\frac{dx}{dt} = f(t, x) \text{, } x(t_0) = x_0
	\]

tiene al menos una solución en $I_{\alpha}$ con $\alpha = \min \left\{ a, b/M \right\}$

\end{theorem}

\textbf{Demostración:} PENDIENTE.

\begin{flushright}
	$\Box$
\end{flushright}


Para finalizar esta sección, se hablará un poco de ecuaciones diferenciales controladas, que también, son parte importante al hablar de caminos rugosos...

% INTEGRACIÓN.

% Integración usual RS, Integral de Young. Conceptos de p-variación y $\alpha$-Hölder. OK.*

% Ecuaciones Diferenciales Ordinarias. EDO Controladas. OK

% Teorema de Picard, Teorema de Peano. OK


\input{C1/TG_C1_EXTRA}
